{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTJSG3VNmVkIWiyBc1mLid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eswa2020/Data-analysis-and-wrangling-various-projects/blob/master/PARKING_SYSTEM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries and loading dataset"
      ],
      "metadata": {
        "id": "ZiqXGwKRE7n-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IU1hju9zhoMB"
      },
      "outputs": [],
      "source": [
        "#importimg our libraries to use\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UvFW9hPDi8qO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ea4a35-a349-44f8-ec3f-690e7f32a965"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "geK83kw3gRux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c2a1bf50-ba3e-4875-dc86-cbd569619977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   DeviceId             ArrivalTime           DepartureTime  DurationMinutes  \\\n",
              "0     17176  02/15/2019 07:45:29 PM  02/15/2019 07:46:52 PM                1   \n",
              "1     17176  03/25/2019 08:35:40 PM  03/25/2019 08:39:08 PM                4   \n",
              "2     17176  01/17/2019 05:28:55 AM  01/17/2019 06:57:09 AM               89   \n",
              "3     17176  03/13/2019 10:18:17 PM  03/13/2019 10:18:24 PM                0   \n",
              "4     17176  01/18/2019 06:04:37 AM  01/18/2019 06:07:29 AM                3   \n",
              "\n",
              "  StreetMarker  SignPlateID Sign   AreaName  StreetId      StreetName  \\\n",
              "0       13009S          NaN  NaN  Docklands       528  COLLINS STREET   \n",
              "1       13009S          NaN  NaN  Docklands       528  COLLINS STREET   \n",
              "2       13009S          NaN  NaN  Docklands       528  COLLINS STREET   \n",
              "3       13009S          NaN  NaN  Docklands       528  COLLINS STREET   \n",
              "4       13009S          NaN  NaN  Docklands       528  COLLINS STREET   \n",
              "\n",
              "   BetweenStreet1ID  BetweenStreet1  BetweenStreet2ID      BetweenStreet2  \\\n",
              "0              1285  SPENCER STREET                79  BATMANS HILL DRIVE   \n",
              "1              1285  SPENCER STREET                79  BATMANS HILL DRIVE   \n",
              "2              1285  SPENCER STREET                79  BATMANS HILL DRIVE   \n",
              "3              1285  SPENCER STREET                79  BATMANS HILL DRIVE   \n",
              "4              1285  SPENCER STREET                79  BATMANS HILL DRIVE   \n",
              "\n",
              "   SideOfStreet SideOfStreetCode SideName  BayId  InViolation  VehiclePresent  \n",
              "0             4                S    South   6005        False            True  \n",
              "1             4                S    South   6005        False            True  \n",
              "2             4                S    South   6005        False            True  \n",
              "3             4                S    South   6005        False           False  \n",
              "4             4                S    South   6005        False            True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52ab0d40-b876-4db3-9aca-225b88161819\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DeviceId</th>\n",
              "      <th>ArrivalTime</th>\n",
              "      <th>DepartureTime</th>\n",
              "      <th>DurationMinutes</th>\n",
              "      <th>StreetMarker</th>\n",
              "      <th>SignPlateID</th>\n",
              "      <th>Sign</th>\n",
              "      <th>AreaName</th>\n",
              "      <th>StreetId</th>\n",
              "      <th>StreetName</th>\n",
              "      <th>BetweenStreet1ID</th>\n",
              "      <th>BetweenStreet1</th>\n",
              "      <th>BetweenStreet2ID</th>\n",
              "      <th>BetweenStreet2</th>\n",
              "      <th>SideOfStreet</th>\n",
              "      <th>SideOfStreetCode</th>\n",
              "      <th>SideName</th>\n",
              "      <th>BayId</th>\n",
              "      <th>InViolation</th>\n",
              "      <th>VehiclePresent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17176</td>\n",
              "      <td>02/15/2019 07:45:29 PM</td>\n",
              "      <td>02/15/2019 07:46:52 PM</td>\n",
              "      <td>1</td>\n",
              "      <td>13009S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>528</td>\n",
              "      <td>COLLINS STREET</td>\n",
              "      <td>1285</td>\n",
              "      <td>SPENCER STREET</td>\n",
              "      <td>79</td>\n",
              "      <td>BATMANS HILL DRIVE</td>\n",
              "      <td>4</td>\n",
              "      <td>S</td>\n",
              "      <td>South</td>\n",
              "      <td>6005</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17176</td>\n",
              "      <td>03/25/2019 08:35:40 PM</td>\n",
              "      <td>03/25/2019 08:39:08 PM</td>\n",
              "      <td>4</td>\n",
              "      <td>13009S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>528</td>\n",
              "      <td>COLLINS STREET</td>\n",
              "      <td>1285</td>\n",
              "      <td>SPENCER STREET</td>\n",
              "      <td>79</td>\n",
              "      <td>BATMANS HILL DRIVE</td>\n",
              "      <td>4</td>\n",
              "      <td>S</td>\n",
              "      <td>South</td>\n",
              "      <td>6005</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17176</td>\n",
              "      <td>01/17/2019 05:28:55 AM</td>\n",
              "      <td>01/17/2019 06:57:09 AM</td>\n",
              "      <td>89</td>\n",
              "      <td>13009S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>528</td>\n",
              "      <td>COLLINS STREET</td>\n",
              "      <td>1285</td>\n",
              "      <td>SPENCER STREET</td>\n",
              "      <td>79</td>\n",
              "      <td>BATMANS HILL DRIVE</td>\n",
              "      <td>4</td>\n",
              "      <td>S</td>\n",
              "      <td>South</td>\n",
              "      <td>6005</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17176</td>\n",
              "      <td>03/13/2019 10:18:17 PM</td>\n",
              "      <td>03/13/2019 10:18:24 PM</td>\n",
              "      <td>0</td>\n",
              "      <td>13009S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>528</td>\n",
              "      <td>COLLINS STREET</td>\n",
              "      <td>1285</td>\n",
              "      <td>SPENCER STREET</td>\n",
              "      <td>79</td>\n",
              "      <td>BATMANS HILL DRIVE</td>\n",
              "      <td>4</td>\n",
              "      <td>S</td>\n",
              "      <td>South</td>\n",
              "      <td>6005</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17176</td>\n",
              "      <td>01/18/2019 06:04:37 AM</td>\n",
              "      <td>01/18/2019 06:07:29 AM</td>\n",
              "      <td>3</td>\n",
              "      <td>13009S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>528</td>\n",
              "      <td>COLLINS STREET</td>\n",
              "      <td>1285</td>\n",
              "      <td>SPENCER STREET</td>\n",
              "      <td>79</td>\n",
              "      <td>BATMANS HILL DRIVE</td>\n",
              "      <td>4</td>\n",
              "      <td>S</td>\n",
              "      <td>South</td>\n",
              "      <td>6005</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52ab0d40-b876-4db3-9aca-225b88161819')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52ab0d40-b876-4db3-9aca-225b88161819 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52ab0d40-b876-4db3-9aca-225b88161819');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#let's load the  dataset \n",
        "dataq=pd.read_csv(\"/content/drive/MyDrive/melbourne_parking_data.csv\",encoding='ISO-8859-1')\n",
        "dataq.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "VMQcrR4gd-P1",
        "outputId": "b5bbbe78-f566-4692-88e1-c142cbd6dbc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         DeviceId             ArrivalTime           DepartureTime  \\\n",
              "1048570     17419  01/21/2019 07:17:38 AM  01/21/2019 07:30:00 AM   \n",
              "1048571     17418  11/18/2019 10:05:57 PM  11/18/2019 10:07:31 PM   \n",
              "1048572     17420  06/13/2019 09:30:00 AM  06/13/2019 10:02:23 AM   \n",
              "1048573     17418  05/15/2019 04:31:54 PM  05/15/2019 04:32:56 PM   \n",
              "1048574     17418  05/25/2019 06:10:25 PM  05/25/2019 06:18:14 PM   \n",
              "\n",
              "         DurationMinutes StreetMarker  SignPlateID                   Sign  \\\n",
              "1048570               13       13398E          NaN                    NaN   \n",
              "1048571                2       13397W          NaN                    NaN   \n",
              "1048572               32       13399W         99.0  2P MTR M-F 9:30-16:00   \n",
              "1048573                1       13397W        430.0   1/4P M-F 16:00-18:30   \n",
              "1048574                8       13397W        362.0  1P SAT-SUN 7:30-18:30   \n",
              "\n",
              "          AreaName  StreetId          StreetName  BetweenStreet1ID  \\\n",
              "1048570  Docklands        79  BATMANS HILL DRIVE              1457   \n",
              "1048571  Docklands      1383      VILLAGE STREET               131   \n",
              "1048572  Docklands      1383      VILLAGE STREET               131   \n",
              "1048573  Docklands      1383      VILLAGE STREET               131   \n",
              "1048574  Docklands      1383      VILLAGE STREET               131   \n",
              "\n",
              "         BetweenStreet1  BetweenStreet2ID  BetweenStreet2  SideOfStreet  \\\n",
              "1048570  FISHPLATE LANE               528  COLLINS STREET             2   \n",
              "1048571    BRENTANI WAY               974   MCCRAE STREET             5   \n",
              "1048572    BRENTANI WAY               974   MCCRAE STREET             5   \n",
              "1048573    BRENTANI WAY               974   MCCRAE STREET             5   \n",
              "1048574    BRENTANI WAY               974   MCCRAE STREET             5   \n",
              "\n",
              "        SideOfStreetCode SideName  BayId  InViolation  VehiclePresent  \n",
              "1048570                E     East   6656        False            True  \n",
              "1048571                W     West   6320        False           False  \n",
              "1048572                W     West   6321        False            True  \n",
              "1048573                W     West   6320        False           False  \n",
              "1048574                W     West   6320        False            True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7601956-8341-44d3-800c-e12a4307bf96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DeviceId</th>\n",
              "      <th>ArrivalTime</th>\n",
              "      <th>DepartureTime</th>\n",
              "      <th>DurationMinutes</th>\n",
              "      <th>StreetMarker</th>\n",
              "      <th>SignPlateID</th>\n",
              "      <th>Sign</th>\n",
              "      <th>AreaName</th>\n",
              "      <th>StreetId</th>\n",
              "      <th>StreetName</th>\n",
              "      <th>BetweenStreet1ID</th>\n",
              "      <th>BetweenStreet1</th>\n",
              "      <th>BetweenStreet2ID</th>\n",
              "      <th>BetweenStreet2</th>\n",
              "      <th>SideOfStreet</th>\n",
              "      <th>SideOfStreetCode</th>\n",
              "      <th>SideName</th>\n",
              "      <th>BayId</th>\n",
              "      <th>InViolation</th>\n",
              "      <th>VehiclePresent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>17419</td>\n",
              "      <td>01/21/2019 07:17:38 AM</td>\n",
              "      <td>01/21/2019 07:30:00 AM</td>\n",
              "      <td>13</td>\n",
              "      <td>13398E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>79</td>\n",
              "      <td>BATMANS HILL DRIVE</td>\n",
              "      <td>1457</td>\n",
              "      <td>FISHPLATE LANE</td>\n",
              "      <td>528</td>\n",
              "      <td>COLLINS STREET</td>\n",
              "      <td>2</td>\n",
              "      <td>E</td>\n",
              "      <td>East</td>\n",
              "      <td>6656</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>17418</td>\n",
              "      <td>11/18/2019 10:05:57 PM</td>\n",
              "      <td>11/18/2019 10:07:31 PM</td>\n",
              "      <td>2</td>\n",
              "      <td>13397W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>1383</td>\n",
              "      <td>VILLAGE STREET</td>\n",
              "      <td>131</td>\n",
              "      <td>BRENTANI WAY</td>\n",
              "      <td>974</td>\n",
              "      <td>MCCRAE STREET</td>\n",
              "      <td>5</td>\n",
              "      <td>W</td>\n",
              "      <td>West</td>\n",
              "      <td>6320</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>17420</td>\n",
              "      <td>06/13/2019 09:30:00 AM</td>\n",
              "      <td>06/13/2019 10:02:23 AM</td>\n",
              "      <td>32</td>\n",
              "      <td>13399W</td>\n",
              "      <td>99.0</td>\n",
              "      <td>2P MTR M-F 9:30-16:00</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>1383</td>\n",
              "      <td>VILLAGE STREET</td>\n",
              "      <td>131</td>\n",
              "      <td>BRENTANI WAY</td>\n",
              "      <td>974</td>\n",
              "      <td>MCCRAE STREET</td>\n",
              "      <td>5</td>\n",
              "      <td>W</td>\n",
              "      <td>West</td>\n",
              "      <td>6321</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>17418</td>\n",
              "      <td>05/15/2019 04:31:54 PM</td>\n",
              "      <td>05/15/2019 04:32:56 PM</td>\n",
              "      <td>1</td>\n",
              "      <td>13397W</td>\n",
              "      <td>430.0</td>\n",
              "      <td>1/4P M-F 16:00-18:30</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>1383</td>\n",
              "      <td>VILLAGE STREET</td>\n",
              "      <td>131</td>\n",
              "      <td>BRENTANI WAY</td>\n",
              "      <td>974</td>\n",
              "      <td>MCCRAE STREET</td>\n",
              "      <td>5</td>\n",
              "      <td>W</td>\n",
              "      <td>West</td>\n",
              "      <td>6320</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>17418</td>\n",
              "      <td>05/25/2019 06:10:25 PM</td>\n",
              "      <td>05/25/2019 06:18:14 PM</td>\n",
              "      <td>8</td>\n",
              "      <td>13397W</td>\n",
              "      <td>362.0</td>\n",
              "      <td>1P SAT-SUN 7:30-18:30</td>\n",
              "      <td>Docklands</td>\n",
              "      <td>1383</td>\n",
              "      <td>VILLAGE STREET</td>\n",
              "      <td>131</td>\n",
              "      <td>BRENTANI WAY</td>\n",
              "      <td>974</td>\n",
              "      <td>MCCRAE STREET</td>\n",
              "      <td>5</td>\n",
              "      <td>W</td>\n",
              "      <td>West</td>\n",
              "      <td>6320</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7601956-8341-44d3-800c-e12a4307bf96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7601956-8341-44d3-800c-e12a4307bf96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7601956-8341-44d3-800c-e12a4307bf96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataq.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring our dataset"
      ],
      "metadata": {
        "id": "K70_62MCFOJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5JC-BkIhzCY",
        "outputId": "5ee17126-848f-4aae-ff92-c12159055fe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1048575, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataq.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq_XDx4kqiXI",
        "outputId": "5fa6e524-b3ad-44e2-ca9c-a93996cd5e68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceId                 0\n",
              "ArrivalTime              0\n",
              "DepartureTime            0\n",
              "DurationMinutes          0\n",
              "StreetMarker             0\n",
              "SignPlateID         286382\n",
              "Sign                286382\n",
              "AreaName                 1\n",
              "StreetId                 0\n",
              "StreetName               0\n",
              "BetweenStreet1ID         0\n",
              "BetweenStreet1           0\n",
              "BetweenStreet2ID         0\n",
              "BetweenStreet2           0\n",
              "SideOfStreet             0\n",
              "SideOfStreetCode         0\n",
              "SideName                 0\n",
              "BayId                    0\n",
              "InViolation              0\n",
              "VehiclePresent           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataq.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXIf3JWeqx0Y",
        "outputId": "df12fc21-621e-4da3-aef0-eb093be732ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "407"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataq.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNajnJmfbfUP",
        "outputId": "4fbbfd62-8dad-4252-ec64-c53784cea213"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceId              int64\n",
              "ArrivalTime          object\n",
              "DepartureTime        object\n",
              "DurationMinutes       int64\n",
              "StreetMarker         object\n",
              "SignPlateID         float64\n",
              "Sign                 object\n",
              "AreaName             object\n",
              "StreetId              int64\n",
              "StreetName           object\n",
              "BetweenStreet1ID      int64\n",
              "BetweenStreet1       object\n",
              "BetweenStreet2ID      int64\n",
              "BetweenStreet2       object\n",
              "SideOfStreet          int64\n",
              "SideOfStreetCode     object\n",
              "SideName             object\n",
              "BayId                 int64\n",
              "InViolation            bool\n",
              "VehiclePresent         bool\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dataq.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LQggV6jsRvX",
        "outputId": "a370f0b3-27d8-473d-f175-530bb77bccf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of          DeviceId             ArrivalTime           DepartureTime  \\\n",
              "0           17176  02/15/2019 07:45:29 PM  02/15/2019 07:46:52 PM   \n",
              "1           17176  03/25/2019 08:35:40 PM  03/25/2019 08:39:08 PM   \n",
              "2           17176  01/17/2019 05:28:55 AM  01/17/2019 06:57:09 AM   \n",
              "3           17176  03/13/2019 10:18:17 PM  03/13/2019 10:18:24 PM   \n",
              "4           17176  01/18/2019 06:04:37 AM  01/18/2019 06:07:29 AM   \n",
              "...           ...                     ...                     ...   \n",
              "1048570     17419  01/21/2019 07:17:38 AM  01/21/2019 07:30:00 AM   \n",
              "1048571     17418  11/18/2019 10:05:57 PM  11/18/2019 10:07:31 PM   \n",
              "1048572     17420  06/13/2019 09:30:00 AM  06/13/2019 10:02:23 AM   \n",
              "1048573     17418  05/15/2019 04:31:54 PM  05/15/2019 04:32:56 PM   \n",
              "1048574     17418  05/25/2019 06:10:25 PM  05/25/2019 06:18:14 PM   \n",
              "\n",
              "         DurationMinutes StreetMarker  SignPlateID                   Sign  \\\n",
              "0                      1       13009S          NaN                    NaN   \n",
              "1                      4       13009S          NaN                    NaN   \n",
              "2                     89       13009S          NaN                    NaN   \n",
              "3                      0       13009S          NaN                    NaN   \n",
              "4                      3       13009S          NaN                    NaN   \n",
              "...                  ...          ...          ...                    ...   \n",
              "1048570               13       13398E          NaN                    NaN   \n",
              "1048571                2       13397W          NaN                    NaN   \n",
              "1048572               32       13399W         99.0  2P MTR M-F 9:30-16:00   \n",
              "1048573                1       13397W        430.0   1/4P M-F 16:00-18:30   \n",
              "1048574                8       13397W        362.0  1P SAT-SUN 7:30-18:30   \n",
              "\n",
              "          AreaName  StreetId          StreetName  BetweenStreet1ID  \\\n",
              "0        Docklands       528      COLLINS STREET              1285   \n",
              "1        Docklands       528      COLLINS STREET              1285   \n",
              "2        Docklands       528      COLLINS STREET              1285   \n",
              "3        Docklands       528      COLLINS STREET              1285   \n",
              "4        Docklands       528      COLLINS STREET              1285   \n",
              "...            ...       ...                 ...               ...   \n",
              "1048570  Docklands        79  BATMANS HILL DRIVE              1457   \n",
              "1048571  Docklands      1383      VILLAGE STREET               131   \n",
              "1048572  Docklands      1383      VILLAGE STREET               131   \n",
              "1048573  Docklands      1383      VILLAGE STREET               131   \n",
              "1048574  Docklands      1383      VILLAGE STREET               131   \n",
              "\n",
              "         BetweenStreet1  BetweenStreet2ID      BetweenStreet2  SideOfStreet  \\\n",
              "0        SPENCER STREET                79  BATMANS HILL DRIVE             4   \n",
              "1        SPENCER STREET                79  BATMANS HILL DRIVE             4   \n",
              "2        SPENCER STREET                79  BATMANS HILL DRIVE             4   \n",
              "3        SPENCER STREET                79  BATMANS HILL DRIVE             4   \n",
              "4        SPENCER STREET                79  BATMANS HILL DRIVE             4   \n",
              "...                 ...               ...                 ...           ...   \n",
              "1048570  FISHPLATE LANE               528      COLLINS STREET             2   \n",
              "1048571    BRENTANI WAY               974       MCCRAE STREET             5   \n",
              "1048572    BRENTANI WAY               974       MCCRAE STREET             5   \n",
              "1048573    BRENTANI WAY               974       MCCRAE STREET             5   \n",
              "1048574    BRENTANI WAY               974       MCCRAE STREET             5   \n",
              "\n",
              "        SideOfStreetCode SideName  BayId  InViolation  VehiclePresent  \n",
              "0                      S    South   6005        False            True  \n",
              "1                      S    South   6005        False            True  \n",
              "2                      S    South   6005        False            True  \n",
              "3                      S    South   6005        False           False  \n",
              "4                      S    South   6005        False            True  \n",
              "...                  ...      ...    ...          ...             ...  \n",
              "1048570                E     East   6656        False            True  \n",
              "1048571                W     West   6320        False           False  \n",
              "1048572                W     West   6321        False            True  \n",
              "1048573                W     West   6320        False           False  \n",
              "1048574                W     West   6320        False            True  \n",
              "\n",
              "[1048575 rows x 20 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataq.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWAny4J5a6wD"
      },
      "source": [
        "##Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class distribution**\n",
        "First, let’s look at the frequency distribution by parking zones (see Figure 3). Unsurprisingly, Zone 1 was most common since we would always try to find a parking space closest to my apartment block. The distribution also suggests a class imbalance, something to take into consideration when building and evaluating an ML model.\n",
        "\n"
      ],
      "metadata": {
        "id": "IqY-t7UkYO9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hour of the day**\n",
        "Next, let’s look at the percentage of parking sessions across different hours of the day by parking zones (see Figure 4). The later I returned home, the more unlikely it was to find parking space in Zone 1. This was common sense, but it was good to know that the data I collected validated this observation. Based on Figure 4, it also appeared that hour could be a useful feature in predicting parking availability."
      ],
      "metadata": {
        "id": "RReSA9GdYdRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day of the week**\n",
        "I also asked myself, “Are there certain days of the week where it is less probable to find a parking space in Zone 1?” Based on the data collected, yes! The probability of getting a parking space in Zone 1 was the highest on Mondays (~83%), decreased over the week days and was the lowest on Thursdays (~59%) and Sundays (~61%). Thus, day_of_week could also be a useful predictor for parking availability."
      ],
      "metadata": {
        "id": "yGaVsWbbYl1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Public holiday, eve, or neither?**\n",
        "Through out the data collection period, it felt like it was harder to find a parking space in Zone 1 on public holidays. I guessed it was because the next day could be a working/schooling day and residents tend to stay home. The opposite was true for public holiday eves, meaning residents might not return home early since the next day was a public holiday."
      ],
      "metadata": {
        "id": "h0idzjOeYfCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20Xj2B9JbAs2"
      },
      "outputs": [],
      "source": [
        "#since the data is mostly clean we start with changing the date column from\"object\"to\"date\"\n",
        "#convert column to datetime pandas\n",
        "dataq['ArrivalTime'] = pd.to_datetime(dataq['ArrivalTime'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lT3XrUPWcQ-9"
      },
      "outputs": [],
      "source": [
        "#since the data is mostly clean we start with changing the date column from\"object\"to\"date\"\n",
        "#convert column to datetime pandas\n",
        "dataq['DepartureTime'] = pd.to_datetime(dataq['DepartureTime'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn7PJSXwgSbw"
      },
      "outputs": [],
      "source": [
        "dataq.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98Tgpyz8gXuv"
      },
      "outputs": [],
      "source": [
        "#we drop all unnecessary columns,we first drop signplateID Since we wont need it in our analysis\n",
        "#also we drop all other primary key columns sinceon eis enough\n",
        "#SignPlateID ,StreetId,BayId \n",
        "\n",
        "dataq.drop(columns=[\"Sign\",\"SignPlateID\",\"BetweenStreet1\",\"BetweenStreet2\",\"BetweenStreet1ID\",\"BetweenStreet2ID\"] ,axis=1, inplace=True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataq.drop(columns=[\"StreetId\",\"StreetMarker\",\"SideOfStreet\",\"SideOfStreetCode\",\"SideName\"] ,axis=1, inplace=True) "
      ],
      "metadata": {
        "id": "RRDfcedlBJZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfFMXl7YX0gv"
      },
      "outputs": [],
      "source": [
        "#also drop all the null values\n",
        "# using dropna() function  \n",
        "dataq.dropna()\n",
        "dataq.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW5LnMuGYbr2"
      },
      "outputs": [],
      "source": [
        "dataq.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keF9VOGfjTMP"
      },
      "outputs": [],
      "source": [
        "print(dataq.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXfETGKumCkJ"
      },
      "outputs": [],
      "source": [
        "#Exctract month and create a dedicated column df[\"Month\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['Month'] = pd.DatetimeIndex(dataq['ArrivalTime']).month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3oyMZPzmRLp"
      },
      "outputs": [],
      "source": [
        "#Exctract month and create a dedicated column df[\"Month\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['Year'] = pd.DatetimeIndex(dataq['ArrivalTime']).year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN612pQ9Txv9"
      },
      "outputs": [],
      "source": [
        "#Exctract day and create a dedicated column df[\"Day\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['Day'] = pd.DatetimeIndex(dataq['DepartureTime']).day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6IOl6XNU5PN"
      },
      "outputs": [],
      "source": [
        "#Exctract day and create a dedicated column df[\"Day\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['hourarrive'] = pd.DatetimeIndex(dataq['ArrivalTime']).hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwYnouVvVAXU"
      },
      "outputs": [],
      "source": [
        "#Exctract day and create a dedicated column df[\"Day\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['secondarrive'] = pd.DatetimeIndex(dataq['ArrivalTime']).second"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX68YBW5VHgx"
      },
      "outputs": [],
      "source": [
        "#Exctract day and create a dedicated column df[\"Day\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['minutearrive'] = pd.DatetimeIndex(dataq['ArrivalTime']).minute"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exctract day and create a dedicated column df[\"Day\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['seconddepart'] = pd.DatetimeIndex(dataq['DepartureTime']).second"
      ],
      "metadata": {
        "id": "fVvDyXNpznFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exctract day and create a dedicated column df[\"Day\"] from a \n",
        "#column in datetime format df[\"Date\"]\n",
        "dataq['minutedepart'] = pd.DatetimeIndex(dataq['DepartureTime']).minute"
      ],
      "metadata": {
        "id": "GhhUt6yLzpzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(dataq.columns.tolist())"
      ],
      "metadata": {
        "id": "rF0RvayyctP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8oWeDm2nDT-"
      },
      "source": [
        "##In-depth exploration using SQL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install sqlalchemy\n"
      ],
      "metadata": {
        "id": "yb3HMP33Ig53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# connect to the database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# create engine\n",
        "engine = create_engine('sqlite:///example.db')\n"
      ],
      "metadata": {
        "id": "e8g-9mgNIxK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the sql into our  environment\n",
        "%load_ext sql"
      ],
      "metadata": {
        "id": "s07-CRrMLDeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to our memory sqlite database\n",
        "%sql sqlite://"
      ],
      "metadata": {
        "id": "uPeG1Gl9LKDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we first convert our database into csv so that we can run in the  sql environment\n",
        "# converting to CSV file\n",
        "dataq3=dataq.to_csv('raw_data.csv', index=False)"
      ],
      "metadata": {
        "id": "2qNCFbXRTnZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importimg our libraries to use\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "7khKhhDFdvMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to the database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# create engine\n",
        "engine = create_engine('sqlite:///example.db')\n"
      ],
      "metadata": {
        "id": "1bOEu8g_Ld28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!add-apt-repository -y ppa:sergey-dryabzhinsky/packages\n",
        "!apt update\n",
        "!apt install sqlite3"
      ],
      "metadata": {
        "id": "sOr8xu829A8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "print(sqlite3.sqlite_version) # 3.33.0"
      ],
      "metadata": {
        "id": "YjOqwJ8p9prm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Load data from CSV file into a Pandas DataFrame\n",
        "with open('raw_data.csv', 'r') as f:\n",
        "    data = pd.read_csv(f, index_col=0, encoding='utf-8')\n",
        "\n",
        "# Create a connection to a SQLite database\n",
        "conn = sqlite3.connect('mydatabase.db')\n",
        "\n",
        "# Write the DataFrame to a SQLite table\n",
        "data.to_sql('dataq', conn)\n",
        "\n",
        "# Execute SQL commands on the SQLite table\n",
        "cursor = conn.cursor()\n",
        "cursor.execute('SELECT * FROM dataq3 LIMIT 5;')\n",
        "result = cursor.fetchall()\n",
        "print(result)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "qzeqcO3oFqTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Read data into pandas DataFrame\n",
        "with open('raw_data.csv', 'r') as f:\n",
        "    data = pd.read_csv(f, index_col=0, encoding='utf-8')\n",
        "\n",
        "# Create connection to SQLite database\n",
        "conn = sqlite3.connect('mydatabase.db')\n",
        "\n",
        "# Write DataFrame to SQLite database\n",
        "data.to_sql('mytable', conn)\n",
        "\n",
        "# Query data from SQLite database using SQL\n",
        "sql_query = \"\"\"\n",
        "SELECT * FROM mytable LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "result = pd.read_sql_query(sql_query, conn)\n",
        "\n",
        "# Close connection to SQLite database\n",
        "conn.close()\n",
        "\n",
        "# Show the result\n",
        "result.head()\n"
      ],
      "metadata": {
        "id": "28RwFKPnGcHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we try and get the number of parking stations serving melnbourne city we can also determine if we will use a single or a multi server queue system\n",
        "#Query data from SQLite database using SQL\n",
        "\n",
        "sql_query = \"\"\"\n",
        "SELECT COUNT( DISTINCT DeviceId ) AS \"Number of melb servers\" from mytable;\n",
        "\"\"\"\n",
        "# Create connection to SQLite database\n",
        "conn1 = sqlite3.connect('mydatabase.db')\n",
        "\n",
        "result1 = pd.read_sql_query(sql_query, conn1)\n",
        "\n",
        "# Show the result\n",
        "result1.head()"
      ],
      "metadata": {
        "id": "019fKSCqHTbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We first get the total tarnsactions this also transalates to number of customers served our devices have\n",
        "# Create  another to use connection to SQLite database\n",
        "conn1 = sqlite3.connect('mydatabase.db')\n",
        "\n",
        "# Query data from SQLite database using SQL\n",
        "sql_query = \"\"\"\n",
        "SELECT COUNT(DeviceId) AS \"Number of melb customers\"  FROM mytable;\n",
        "\"\"\"\n",
        "\n",
        "result3 = pd.read_sql_query(sql_query, conn1)\n",
        "\n",
        "\n",
        "# Show the result\n",
        "result3.head()"
      ],
      "metadata": {
        "id": "v1uZbXVdH4D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we try and get the number of areanames that melbourne parking service facilaitates\n",
        "# Create connection to SQLite database\n",
        "conn1 = sqlite3.connect('mydatabase.db')\n",
        "# Query data from SQLite database using SQL\n",
        "sql_query = \"\"\"\n",
        "SELECT COUNT( DISTINCT AreaName ) AS \"Number of Areanames\" FROM mytable;\n",
        "\"\"\"\n",
        "result5= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result5.head()"
      ],
      "metadata": {
        "id": "XwDEbMuGJip8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we try and get the number of streetnames that melbourne parking service facilaitates\n",
        "# Query data from SQLite database using SQL\n",
        "sql_query = \"\"\"\n",
        "SELECT COUNT( DISTINCT StreetName ) AS \"streets of melbourne\" FROM mytable;\n",
        "\"\"\"\n",
        "result5= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result5.head()"
      ],
      "metadata": {
        "id": "w8Z3qelNKGH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we try and get the number of streetnames that melbourne parking service facilaitates\n",
        "# Query data from SQLite database using SQL\n",
        "sql_query = \"\"\"\n",
        "SELECT DeviceId,StreetName,AreaName, COUNT(*) as transactions_per_area FROM mytable GROUP BY AreaName ORDER BY transactions_per_area DESC LIMIT 18;\n",
        "\"\"\"\n",
        "result6= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result6"
      ],
      "metadata": {
        "id": "7d3i5ERMWg3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we also check which device has been used the most in each area and  docklands server 17418 seems to take the fair share of the transactions\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT DeviceId,StreetName,AreaName,hourarrive, COUNT(*) as transactions_per_area FROM mytable GROUP BY AreaName ORDER BY transactions_per_area desc LIMIT 18;\n",
        "\"\"\"\n",
        "result7= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result7.head()\n"
      ],
      "metadata": {
        "id": "CyvYzJJZW-2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we go ahead and determine number of servers in docklands\n",
        "#we then get the how many servers docklands has and it has 228 \n",
        "sql_query = \"\"\"\n",
        "SELECT COUNT( DISTINCT DeviceId ) AS \"Number of docks servers\" from mytable\n",
        "WHERE AreaName=\"Docklands\";\n",
        "\"\"\"\n",
        "# Create connection to SQLite database\n",
        "conn1 = sqlite3.connect('mydatabase.db')\n",
        "\n",
        "result7b = pd.read_sql_query(sql_query, conn1)\n",
        "\n",
        "# Show the result\n",
        "result7b.head()"
      ],
      "metadata": {
        "id": "AufaG9flXaQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we also go ahead and get the number of transactions/customers\n",
        "#docklands has over 95% of transactions in our database\n",
        "# Query data from SQLite database using SQL\n",
        "sql_query = \"\"\"\n",
        "SELECT COUNT(DeviceId) AS \"Number of dock customers\"  FROM mytable\n",
        "WHERE AreaName=\"Docklands\";\n",
        "\"\"\"\n",
        "result7c = pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result7c.head()"
      ],
      "metadata": {
        "id": "LBYm1l0VYKRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also try and get the average parking time on collins streeet\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT AVG(DurationMinutes ) AS \"Average parking time in docklands\" FROM mytable\n",
        "WHERE AreaName=\"Docklands\";\n",
        "\n",
        "\"\"\"\n",
        "result7d= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result7d.head()"
      ],
      "metadata": {
        "id": "uYIM4yg6ZGew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we then check which areanames have high duration periods\n",
        "\n",
        "sql_query = \"\"\"\n",
        "SELECT \tDeviceId,AreaName,COUNT(DISTINCT DurationMinutes)  as duration FROM mytable\n",
        "GROUP BY AreaName\n",
        "ORDER BY \tduration DESC\n",
        "LIMIT 10;\n",
        "\n",
        "\"\"\"\n",
        "result9= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result9.head()"
      ],
      "metadata": {
        "id": "uEz3L-Kfd9PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we then check which areanames have low duration periods\n",
        "\n",
        "sql_query = \"\"\"\n",
        "SELECT \tDeviceId,AreaName,COUNT(DISTINCT DurationMinutes)  as duration FROM mytable\n",
        "GROUP BY AreaName\n",
        "ORDER BY \tduration ASC\n",
        "LIMIT 10;\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result10= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result10.head()"
      ],
      "metadata": {
        "id": "R2VmKMUcefR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we explore docklands futrther cause it is biased  and has 99% of the transactions we first  explore the number of stations in each area and dockalnads has most stations 228\n",
        "sql_query = \"\"\"\n",
        "\n",
        "\n",
        "SELECT DeviceId,AreaName,DurationMinutes,StreetName,BayId,VehiclePresent,Month,Day,hourarrive\n",
        "FROM mytable\n",
        "WHERE AreaName ='Docklands';\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result11= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result11.head()\n"
      ],
      "metadata": {
        "id": "ge0KYuzEZR13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we explore docklands futrther cause it is biased  and has 99% of the transactions we first  explore the number\n",
        "# servers that are busiest and are in which streets\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT StreetName,DeviceId, COUNT(*) FROM mytable\n",
        "GROUP BY DeviceId\n",
        "ORDER BY 3 desc\n",
        "LIMIT 18;\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result12= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result12.head()"
      ],
      "metadata": {
        "id": "FxF1UgeR051a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we explore docklands futrther cause it is biased  and has 99% of the transactions we first  explore the \n",
        "#servers that are least busiest\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT StreetName, COUNT(*) FROM mytable\n",
        "GROUP BY DeviceId\n",
        "ORDER BY 2 asc\n",
        "LIMIT 18;\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result12v= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result12v.head()"
      ],
      "metadata": {
        "id": "0aUmzGzA5Da3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we check which street has the highest number of duration minutes seems it is collins street  \n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT *\n",
        "FROM mytable\n",
        "ORDER BY DurationMinutes desc\n",
        "LIMIT 20;\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result14= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result14.head()"
      ],
      "metadata": {
        "id": "unlFfMyZ2qK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check specifically the server with most transactions in docklands \n",
        "#sever 17195 we discover that its in COLLIN street with bayid=6005\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT *\n",
        "FROM mytable\n",
        "WHERE DeviceId =\"17195\" \n",
        "ORDER BY 3 DESC\n",
        "LIMIT 10;\n",
        "\n",
        "\"\"\"\n",
        "result15= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result15.head()"
      ],
      "metadata": {
        "id": "J3frB2xa3GP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we go ahead and investigate the streetnames in docklands that have duration times of more than 1000 and has a vehicle present\n",
        "#Most vehicles that have the longest duration are packed at midnight\n",
        "#colllins street seems to be most affected \n",
        "#and most vehicles are parked in the month of october\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT DeviceId,ArrivalTime,DurationMinutes,AreaName,StreetName,VehiclePresent\n",
        "FROM mytable\n",
        "WHERE DurationMinutes >\"1000\" AND VehiclePresent=\"1\"\n",
        "ORDER BY 3 desc\n",
        "LIMIT 10;\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "result17= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result17.head()\n"
      ],
      "metadata": {
        "id": "aQeS4G7p6lRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we try and get the number of parking bays on collins street\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT COUNT( DISTINCT BayID ) AS \"Number of bays in collins\" FROM mytable\n",
        "WHERE StreetName=\"COLLINS STREET\";\n",
        "\n",
        "\"\"\"\n",
        "result18= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result18.head()"
      ],
      "metadata": {
        "id": "jw9Umiz7Tjr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we go ahead and investigate collins street\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT *\n",
        "FROM mytable\n",
        "WHERE StreetName=\"COLLINS STREET\"\n",
        "ORDER BY 3 DESC\n",
        "LIMIT 10;\n",
        "\n",
        "\"\"\"\n",
        "result19= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result19.head()"
      ],
      "metadata": {
        "id": "ZzY9sMMRT_2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also try and get number of servers serving collins street\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT COUNT( DISTINCT DeviceId ) AS \"Number of servers in collins\" FROM mytable\n",
        "WHERE StreetName=\"COLLINS STREET\";\n",
        "\n",
        "\"\"\"\n",
        "result20= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result20.head()"
      ],
      "metadata": {
        "id": "HbzDpvfQUb1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also try and get the average parking time on collins streeet\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT AVG(DurationMinutes ) AS \"Average parking time in collins\" FROM mytable\n",
        "WHERE StreetName=\"COLLINS STREET\";\n",
        "\n",
        "\"\"\"\n",
        "result21= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result21.head()"
      ],
      "metadata": {
        "id": "em421OUjUufQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can do the same for village street which holds the server with highest number of transactions\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT COUNT( DISTINCT BayID ) AS \"Number of bays in village\" FROM mytable\n",
        "WHERE StreetName=\"VILLAGE STREET\";\n",
        "\n",
        "\"\"\"\n",
        "result22= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result22.head()"
      ],
      "metadata": {
        "id": "xIkFHcuf5iDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also try and get the average parking time on village street streeet\n",
        "sql_query = \"\"\"\n",
        "\n",
        "SELECT AVG(DurationMinutes ) AS \"Average parking time in village\" FROM mytable\n",
        "WHERE StreetName=\"VILLAGE STREET\";\n",
        "\n",
        "\"\"\"\n",
        "result23= pd.read_sql_query(sql_query, conn1)\n",
        "# Show the result\n",
        "result23.head()"
      ],
      "metadata": {
        "id": "JGgJHOyTVgcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above its an indication that we our model can only follow multiserver model queing system since most most the cars(90& and above) the parking station in the docklands.\n",
        "Multiserver queue system must hab other characteristics\n",
        " \n",
        " All the parking stations are assumed to work at the identical capacity.\n",
        "\n",
        "*   The arrival of cars follows the poisson distribution \n",
        " \n",
        "*   Parking stations service follows the exponential distribution.\n",
        "\n",
        "*  All the parking stations are assumed to work at the identical capacity.\n"
      ],
      "metadata": {
        "id": "K1pthI0JZZhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Analysis"
      ],
      "metadata": {
        "id": "_TXczeulV2PA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vehicle present indicates whether a car is present or not we first analyse car presence analysis and percentage"
      ],
      "metadata": {
        "id": "ezLVMYDpCXx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load parking data into a DataFrame\n",
        "#data = dataq\n",
        "# Analyze the column indicating car presence\n",
        "car_presence_counts = data[\"VehiclePresent\"].value_counts()\n",
        "\n",
        "# Calculate car presence percentage\n",
        "car_presence_percentage = car_presence_counts / len(data) * 100\n",
        "\n",
        "# Print the analysis results\n",
        "print(\"Car Presence Analysis:\")\n",
        "print(car_presence_counts)\n",
        "print(\"\\nCar Presence Percentage:\")\n",
        "print(car_presence_percentage)\n"
      ],
      "metadata": {
        "id": "dk7LnAxhBojt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a bar plot to visualize the car presence for different months:"
      ],
      "metadata": {
        "id": "etzrVUOMG5wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "29WlbuwWG-Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Group the data by month and calculate the car presence counts for each month\n",
        "car_presence_counts = dataq.groupby(\"Month\")[\"VehiclePresent\"].sum()"
      ],
      "metadata": {
        "id": "ZBTuBCmiHa_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a bar plot to visualize the car presence for different months\n",
        "plt.bar(car_presence_counts.index, car_presence_counts.values)\n",
        "plt.xlabel(\"Month\")\n",
        "plt.ylabel(\"Vehicle Presence\")\n",
        "plt.title(\"Car Presence by Month\")\n",
        "plt.xticks(range(1, 13))  # Assuming the months are represented by numbers 1-12\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ycQn9AfBJd_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataq.head()"
      ],
      "metadata": {
        "id": "k9SyZSS9s80d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import important libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "itbIH1t0t3Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pivot the data to create a matrix where each row represents a day\n",
        "#each column represents an hour, and the values represent the parking occupancy:\n",
        "pivot_data = dataq.pivot_table(index=\"Month\", columns=\"hourarrive\", values=\"VehiclePresent\", aggfunc=np.mean)"
      ],
      "metadata": {
        "id": "zPJjhtKAsh-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform clustering on the pivot data. Set the number of clusters and fit the K-means clustering algorithm:\n",
        "num_clusters = 4  # Choose the appropriate number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
        "kmeans.fit(pivot_data.values)\n",
        "cluster_labels = kmeans.labels_"
      ],
      "metadata": {
        "id": "MVKsM2FItYQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the clustering results using a heatmap:\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(pivot_data.values, cmap=\"hot\")\n",
        "plt.colorbar(label=\"Occupancy\")\n",
        "plt.xticks(np.arange(24), np.arange(24))\n",
        "plt.yticks(np.arange(12), [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\n",
        "plt.xlabel(\"Hour\")\n",
        "plt.ylabel(\"Month\")\n",
        "plt.title(\"Clustering of Parking Occupancy by Hour\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_-yEArKxtnnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have generated a heatmap plot where each cell represents the average parking occupancy for a specific hour in a specific month. The color intensity represents the occupancy level, and the clustering analysis is reflected in the patterns and clusters observed in the heatmap."
      ],
      "metadata": {
        "id": "-9mYRyc5ucod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "weekly aps curve plot"
      ],
      "metadata": {
        "id": "pcEoMRPhKPIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import important libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "56qqRWUwxZbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the day of the week from the \"timestamp\" column and calculate the average occupancy for each day of the week:\n",
        "data[\"day_of_week\"] = dataq[\"ArrivalTime\"].dt.day_of_week\n",
        "weekly_occupancy = data.groupby(\"day_of_week\")[\"VehiclePresent\"].mean()\n"
      ],
      "metadata": {
        "id": "3ETEsd-N6ksS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a weekly APS curve plot:\n",
        "weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "\n",
        "plt.plot(weekdays, weekly_occupancy)\n",
        "plt.xlabel(\"Day of the Week\")\n",
        "plt.ylabel(\"Average Occupancy\")\n",
        "plt.title(\"Weekly APS Curve Analysis\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F6sZ1D3o64LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a bar plot to visualize the car presence for different days:"
      ],
      "metadata": {
        "id": "rEEm85RGxMGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group the data by month and calculate the car presence counts for each month\n",
        "car_daily_counts = dataq.groupby(\"Day\")[\"VehiclePresent\"].sum()"
      ],
      "metadata": {
        "id": "pA04oiPBKfIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a bar plot to visualize the car presence for different months\n",
        "plt.bar(car_daily_counts.index, car_daily_counts.values)\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Vehicle Presence\")\n",
        "plt.title(\"Daily car presence\")\n",
        "plt.xticks(range(1, 32))  # Assuming the days are represented by numbers 1-31\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3ocilOEWKqEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a bar plot to visualize the car presence for different days:\n"
      ],
      "metadata": {
        "id": "86joklm5LkZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Group the data by duration and calculate the car presence counts for each duration:\n",
        "car_presence_count3 = dataq.groupby(\"DurationMinutes\")[\"VehiclePresent\"].sum()\n",
        "#Create a line plot to visualize the car presence for different duration times\n",
        "plt.plot(car_presence_count3.index, car_presence_count3.values)\n",
        "plt.xlabel(\"Duration in minutes\")\n",
        "plt.ylabel(\"car Presence\")\n",
        "plt.title(\"Car Presence by Duration\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9sxVgbtnUDTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "daily and weekly occupancy rate"
      ],
      "metadata": {
        "id": "yJVp6Rt8_Lqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the week of the year and hour of the day from the \"timestamp\" column:\n",
        "data[\"week_of_year\"] = dataq[\"ArrivalTime\"].dt.week\n",
        "data[\"hour_of_day\"] = dataq[\"ArrivalTime\"].dt.hour\n"
      ],
      "metadata": {
        "id": "DQlNL7tK_QqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the average occupancy for each week of the year and hour of the day:\n",
        "weekly_hourly_occupancy = data.groupby([\"week_of_year\", \"hour_of_day\"])[\"VehiclePresent\"].mean().unstack()\n",
        "#Create a heatmap to visualize the weekly occupancy rates with hours during the day:\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(weekly_hourly_occupancy, cmap=\"hot\", linewidths=0.5, linecolor=\"white\")\n",
        "plt.xlabel(\"Hour of the Day\")\n",
        "plt.ylabel(\"Week of the Year\")\n",
        "plt.title(\"Weekly Occupancy Rates with Hours during the Day\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KPVgfZjL_jPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zct39j_p3FPc"
      },
      "source": [
        "##Bivariate Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering for queuing model"
      ],
      "metadata": {
        "id": "V9dthrm7uSk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** To calculate the arrival rate for a multi-server queuing model, you first need to determine the rate at which customers arrive at the system. This is often denoted as λ (lambda) and can be measured in units of customers per unit of time (e.g., customers per hour).\n",
        "\n",
        "Once you have determined the arrival rate, you can use Little's Law to calculate the average number of customers in the system. Little's Law states that the average number of customers in a system (L) is equal to the arrival rate (λ) multiplied by the average time a customer spends in the system (W). This can be expressed mathematically as L = λW.\n",
        "\n",
        "Once you know the average service time, you can use Little's Law to calculate the average time a customer spends in the system (W) as W = L / λ = 1 / (μ - λ), where μ is the average service rate across all servers\n",
        "\n",
        "In summary, to calculate the arrival rate for a multi-server queuing model, you need to:\n",
        "\n",
        "Determine the arrival rate (λ) of customers to the system.\n",
        "Calculate the average service time (1/μ) across all servers.\n",
        "Use Little's Law to calculate the average time a customer spends in the system (W).\n",
        "Use the traffic intensity formula to calculate the traffic intensity (ρ).\n",
        "Solve for λ using λ = ρ * μ * s.\n",
        "\n",
        "**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R4tBA-i3A29w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.calculating lamba=arival rate(λ)"
      ],
      "metadata": {
        "id": "lheT3uDm7E7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the arrival rate for a multi-server queuing model, you need to know the average number of customers arriving per unit time. This is typically denoted by λ (lambda) and is expressed in units of customers per time interval (e.g., per hour or per day).\n",
        "\n",
        "And since our data is alot we will use per day interval so as to compare with other world cities.\n",
        "\n",
        "To calculate the arrival rate, you can use various methods, such as historical data analysis, customer surveys, or statistical modeling. One common approach is to use a Poisson process, which assumes that customer arrivals occur randomly and independently of one another over time. In our case,the arrival rate is simply the mean number of arrivals per unit time, which can be estimated from our data."
      ],
      "metadata": {
        "id": "1o3Sm7d_1JkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the average arrival rate per customer at each server. This can be calculated as below:\n",
        "\n",
        "In our case you can calculate the average arrival rate by dividing the total number of customers by the time period.\n"
      ],
      "metadata": {
        "id": "r5mvqIj25qm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the total number of customers we had already pre-determined in our analysis\n",
        "total_cust=1048575\n",
        "total_cust"
      ],
      "metadata": {
        "id": "t6RlnQmD5uoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#our intervals is per mimutes since our duration time is in minutes and we need it for utlization factor\n",
        "#our data is from jan to dec of 2019=12\n",
        "#average  daily arrival rate \n",
        "aar=(1048575/365)\n",
        "aar"
      ],
      "metadata": {
        "id": "UCiTYEBYIseK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from our daily arrival rate we covert that per minute rate\n",
        "#∴ 1 1 Per Day = 0.000694444444444444 1 Per Minute\n",
        "aver_at=aar*0.000694444444444444\n",
        "aver_at"
      ],
      "metadata": {
        "id": "emuhaArHIsN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the arrival rate is expressed in different time units, in our case its customers per minute since our duration column is in minutes this will make our analysis easier.\n",
        "\n",
        "So,our arrival rate is 1.99  which is almost 2 customers per minute."
      ],
      "metadata": {
        "id": "SRUglUNqJCMs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.Determine the number of servers in the system.\n",
        "\n"
      ],
      "metadata": {
        "id": "I9a2u4s_5vfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parking sensors can be considered as servers in a queuing model for parking prediction. In a queuing model, there are typically one or more servers that process requests from customers. In the case of parking prediction, the customers are vehicles looking for parking spaces, and the servers are the parking sensors that provide information about the availability of parking spaces.The queuing model can be used to predict the availability of parking spaces based on the number of sensors and the historical data collected by these sensors."
      ],
      "metadata": {
        "id": "kwqcBG76i-xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#number of servers had been pre-determined in our analysis\n",
        "servers=1144\n",
        "servers"
      ],
      "metadata": {
        "id": "K6Am3sAw5yNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Calculating the mu=service time for @ server(μ)"
      ],
      "metadata": {
        "id": "B49vUTnfP642"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the average service time per customer, you need to know the total time that all customers spent being served and the total number of customers served,in our case the total no of customers have already being pre_determined\n",
        "\n",
        "we calculate  the by:\n",
        "\n",
        "Average Service Time per Customer = Total Service Time / Total Number of Customers\n",
        "\n",
        "Total Service Time spent being served = Service Time of Customer 1 + Service Time of Customer 2 + ... + Service Time of Customer n\n",
        "\n",
        "Next, you need to count the total number of customers served:\n",
        "\n",
        "Total Number of Customers = n"
      ],
      "metadata": {
        "id": "-2BP5dx_am2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#total service time will be the sum of the duration column of our data which is in minutes \n",
        "serv_t = sum(dataq['DurationMinutes'])\n",
        "serv_t"
      ],
      "metadata": {
        "id": "m4w8s0Lxan8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to get the average time per customer we take the total service time and divide by total customers served which is already predetermined\n",
        "avg_serv_t=(serv_t/total_cust)\n",
        "avg_serv_t"
      ],
      "metadata": {
        "id": "Efz-QXN-J2Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the average time customers are taking in our service or system is an average of 47.99 or approx 48minutes per customer\n"
      ],
      "metadata": {
        "id": "4OIY_s9DKlO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.utilization factor"
      ],
      "metadata": {
        "id": "_zoF53z5QU_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the utilization factor, which is the ratio of the average service time to the average inter-arrival time. This can be done using the following formula:\n",
        "\n",
        "Utilization Factor = (Average Service Time) * (Number of Servers) / (Average Inter-arrival Time)\n",
        "\n"
      ],
      "metadata": {
        "id": "ye5M_cXj5zRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the arrival rate using the following formula:\n",
        "\n",
        "Arrival Rate = Utilization Factor * Server Capacity\n",
        "\n",
        "where Server Capacity is the maximum number of customers that can be served simultaneously by the system."
      ],
      "metadata": {
        "id": "zBJK8NDn54el"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally to get our utilization factor\n",
        "#we then get the arrival rateb which we have calculated above \n",
        "#server capacity=average service time per customer which we also have\n",
        "#Factor=aver_at/server_capacity\n",
        "#server_capacity=number of servers*average service time\n",
        "server_capacity=servers*avg_serv_t\n",
        "server_capacity"
      ],
      "metadata": {
        "id": "5LemsrgA5-Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Factor=aver_at/server_capacity\n",
        "Factor"
      ],
      "metadata": {
        "id": "PHeGL3woPIfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have determined the arrival rate, you can use this information along with other parameters, such as the service rate, the number of servers, and the queue capacity, to analyze the performance of the system and make predictions about wait times, queue lengths, and other metrics explained below.\n"
      ],
      "metadata": {
        "id": "7A0aRCnV8Feb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics of success for queuing model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ogQ1-1a05-cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi server queue has two or more service facility in parallel providing identical service. All the\n",
        "customers in the waiting line can be served by more than one station. The arrival time and the service time\n",
        "follow poison and exponential distribution.(FCFS queue model)\n",
        "\n",
        "Once you have estimated the arrival rate, you can use it along with other system parameters to calculate key performance metrics, such as the average wait time in the queue, the average number of customers in the system, and the probability of the system being in different states (e.g., idle, busy, or overloaded)\n",
        "\n",
        "These metrics can be used to evaluate the system's efficiency and identify areas for improvement.Overall, a successful multi-server queuing model should have high utilization, low queue length, short waiting times, fast service times, high throughput, and low abandonment rates.\n",
        "\n",
        "We are going to analyse the following metrics for our system:\n",
        "\n",
        "* Average waiting time: \n",
        "\n",
        "* Queue length: \n",
        "\n",
        "* Service utilization: \n",
        "\n",
        "* Throughput: \n",
        "\n",
        "* Resource utilization: \n",
        "\n",
        "* System capacity: \n",
        "\n",
        "* Service level: \n",
        "\n",
        "* Cost: \n",
        "\n",
        "Overall, the success of a multi-server queuing model will depend on how well it can balance these metrics to meet the needs of the customers and the business."
      ],
      "metadata": {
        "id": "lT1VNu0Y8MOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Average waiting time\n",
        "\n",
        "This metric measures the average amount of time that customers have to wait in the queue before they are served. A shorter waiting time is generally considered to be better."
      ],
      "metadata": {
        "id": "PigFnQRKM9tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The average time a customer spends in the system, W, can be calculated as 1/(μ - λ/N).\n",
        "#Wq, can be calculated as Wq = (ρ * W) / (1 - ρ), where W is the average time a customer spends in the system.\n",
        "#The average time a customer spends in the system, W, can be calculated as 1/(μ - λ/N).\n",
        "#average_waiting_time= 1/(μ - λ/N).\n",
        "#average_waiting_time=1/(serv_tg-(arrival_rate/total_cust)\n",
        "arrival_rate=aver_at\n",
        "t=(arrival_rate/total_cust)\n",
        "t"
      ],
      "metadata": {
        "id": "3iWd5Stm3J4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=serv_t-t\n",
        "y"
      ],
      "metadata": {
        "id": "H22UxcYXFY2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_waiting_t=1/y\n",
        "avg_waiting_t"
      ],
      "metadata": {
        "id": "uULqzzkGFYko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is a really small waiting time which indicates that our customer spend seconds in service"
      ],
      "metadata": {
        "id": "wOLE33RSYSyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.Queue length/Traffic Intensity(p=trafiic intensity(ρ))\n",
        "\n",
        "This metric measures the number of customers waiting in the queue at any given time. A shorter queue length is generally considered to be better."
      ],
      "metadata": {
        "id": "Fo1tHBN8NS7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the queue length in a multi-server queue model with 1144 servers, we already know the arrival rate of customers and the service rate of each server.\n",
        "\n",
        "The customers arrive randomly and independently, and that the service time at each server follows an exponential distribution with a mean of 1/mu, where mu is the service rate, the expected queue length can be approximated by the following formula:"
      ],
      "metadata": {
        "id": "LJhgSjCFThwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ρ = λ / (μ * s), where s is the number of servers. For a stable system, the traffic intensity must be less than 1, so you can solve for λ as λ = ρ * μ * s."
      ],
      "metadata": {
        "id": "E7K961tDW5kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we have already solved for lamba and mu \n",
        "#calaculating for p won be hard =lambda/(mu*server)\n",
        "traf_int=aver_at/(avg_serv_t*servers)\n",
        "traf_int"
      ],
      "metadata": {
        "id": "HIvEkoW13K3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#once we get our rho or tra_int in our case we use it to calculate the queue length as follows\n",
        "#queue_length = (rho**2 + rho) / (1 - rho)\n",
        "queue_length = (traf_int**2 + traf_int) / (1 - traf_int)\n",
        "queue_length\n",
        "print(\"The expected queue length is:\", queue_length)"
      ],
      "metadata": {
        "id": "_VcVpXs-Z-k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this formula, rho is the traffic intensity of the system, which is the ratio of the arrival rate to the product of the number of servers and the service rate. The formula is based on the assumption that the queue length follows a Poisson distribution and that the arrival rate and service rate are constant.\n",
        "\n",
        "NB:our system is stable since it's below 1"
      ],
      "metadata": {
        "id": "-ER1QV0HWt2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The utilization rate (ρ) is calculated using the following formula:\n",
        "#ρ = λ/μ\n",
        "#where ρ is the utilization rate, λ is the arrival rate, and μ is the service rate.\n",
        "ut=aver_at/avg_serv_t\n",
        "ut"
      ],
      "metadata": {
        "id": "Cqc03xr33Ltv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The servers are idle most times as we can see the utilization rate is pretty low at 41.57%"
      ],
      "metadata": {
        "id": "WOM-HfkVYFI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Throughput\n",
        "This metric measures the number of customers served per unit of time. A higher throughput indicates that the system is processing customers more quickly."
      ],
      "metadata": {
        "id": "U1vupxLi1yn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In a multiple server model, the throughput is the number of completed tasks per unit time\n",
        "#using the number of servers n, you can calculate the throughput, which is given by:X = n * μ\n",
        "#Where X is the throughput, n is the number of servers, and μ is the service rate of each server.\n",
        "#Therefore, the formula to calculate the throughput in a multiple server model is:X = n * λ / (1 + (n-1) * (λ/μ))\n",
        "#This formula takes into account the fact that in a multiple server model,\n",
        "#tasks can be serviced simultaneously by multiple servers, which can increase the throughput.\n",
        "tp=(servers*aver_at/(1+(servers-1))*(aver_at/avg_serv_t))\n",
        "tp"
      ],
      "metadata": {
        "id": "tAvflDho3Ntv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that the maximum achievable throughput is limited by the service rate of the servers. \n",
        "\n",
        "In other words, if the service rate of the servers is not high enough to keep up with the arrival rate of customers, the system will experience congestion and the throughput will be reduced.\n",
        "\n",
        "In our case though the throughput is high with being above 82.93%,Its also important to note that its below 90% since the system is not been fully utilized,in other words there is a  reduction in the number of jobs that can be processed per unit time."
      ],
      "metadata": {
        "id": "DIrhudsBbeYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.Resource Utilization\n",
        "\n",
        "This metric measures the percentage of time that each server is in use. A higher resource utilization indicates that the servers are being used more efficiently.Resource utilization refers to the degree to which resources such as servers, facilities, or equipment are used to handle the demand for service. It is a measure of how much of the available resources are being utilized at any given time. Resource utilization is usually expressed as a percentage and is calculated as follows:\n",
        "\n",
        "Resource Utilization = (Total time resources are in use) / (Total time resources are available) * 100%"
      ],
      "metadata": {
        "id": "XqOZj9rOlwm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose we have data on the number of customers served and the time spent in service and queue for a service system over a period of time.\n",
        "customers_served = total_cust\n",
        "time_in_service =serv_t # in minutes\n",
        "time_in_queue = avg_waiting_t # in minutes\n",
        "total_time = time_in_service + time_in_queue # total time in the system\n",
        "\n",
        "# Calculate resource utilization\n",
        "resource_utilization = (time_in_service / total_time) * 100\n",
        "print(\"Resource utilization:\", resource_utilization)\n"
      ],
      "metadata": {
        "id": "30SBqhvWoKUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.Service utilization\n",
        "\n",
        "This metric measures the percentage of time that each server is busy serving customers. A higher service utilization indicates that the servers are being used more efficiently.\n",
        "\n",
        "Service utilization, on the other hand, refers to the degree to which the service system is being used to handle the demand for service. It is a measure of how much of the demand for service is being satisfied by the system at any given time. Service utilization is also usually expressed as a percentage and is calculated as follows:\n",
        "\n",
        "Service Utilization = (Total time spent in service) / (Total time in the system) * 100%"
      ],
      "metadata": {
        "id": "kdF9x3xkm49P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate service utilization\n",
        "service_utilization = (time_in_service / total_time) *100\n",
        "print(\"Service utilization:\", service_utilization)"
      ],
      "metadata": {
        "id": "KvW-vldsm90X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6.System capacity\n",
        "This metric measures the maximum number of customers that the system can handle at any given time. A higher system capacity indicates that the system can handle more customers and is more scalable.\n",
        "\n",
        "Once we have these values, we can calculate the system capacity using the following formula:\n",
        "\n",
        "C = (1 / mu) * rho"
      ],
      "metadata": {
        "id": "C5Nf21ch19Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input values\n",
        "arrival_rate = aver_at\n",
        "service_rate = avg_serv_t\n",
        "\n",
        "# calculate traffic intensity\n",
        "rho = arrival_rate / service_rate\n",
        "\n",
        "# calculate system capacity\n",
        "capacity = (1 / service_rate) * rho\n",
        "\n",
        "print(\"System Capacity:\", capacity)\n"
      ],
      "metadata": {
        "id": "7XXNPD1I3QDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.Service level\n",
        "This metric measures the percentage of customers who receive service within a certain amount of time. A higher service level indicates that customers are receiving timely service.\n",
        "\n",
        "To calculate the service level in a multi-server queueing model, we need to first determine the system's response time distribution, which is the time it takes for a job to be processed from the moment it arrives in the system. This can be calculated by taking into account the arrival rate of jobs, the service time distribution, and the number of servers in the system.\n",
        "The service level can be calculated using the following formula:\n",
        "\n",
        "Service level = Probability (response time <= service level target)\n",
        "\n",
        "Where the response time is the time it takes for a job to be processed from the moment it arrives in the system."
      ],
      "metadata": {
        "id": "lqe6RIOd2i-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#there are 1144 servers=servers\n",
        "#we already have a predetermined arrival rate=aver_at\n",
        "#Define the service time distribution, which is the distribution of time it takes to process a job.\n",
        "#You can use a probability distribution function, in our case we already know its the exponential distribution,to model this parameter. \n",
        "#will take a sample,of the service time an exponential distribution with a mean of (1/λ),\n",
        "#you can use the following code to define the distribution function:\n",
        "#mean=10\n",
        "mean=10\n",
        "mean\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def service_time():\n",
        "    return np.random.exponential(mean)\n",
        "#This function returns a random value from the exponential distribution with a mean of 10  minutes"
      ],
      "metadata": {
        "id": "etqtNyVE3RiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the response time distribution, which is the distribution of time it takes for a job to be processed from \n",
        "#the moment it enters the system. \n",
        "#This can be calculated by taking into account the arrival rate=aver_at of jobs, \n",
        "#the service time distribution, and the number of servers=servers in the system. \n",
        "#You can use the following code to define the response time distribution function:\n",
        "\n",
        "def response_time(servers, aver_at, service_time):\n",
        "    rho=traf_int\n",
        "    response_time_mean = 1 / (servers * (1 - rho))\n",
        "    return np.random.exponential(response_time_mean)\n",
        "\n",
        "#This function returns a random value from the response time distribution based on the number of servers,\n",
        "# arrival rate, and service time distribution."
      ],
      "metadata": {
        "id": "3seC7qtAeFvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simulate the system for a certain number of iterations and calculate the service level.\n",
        "# For example, you can simulate the system for 10,000 iterations and calculate the service level \n",
        "#for a target of 90% service level within 5 minutes using the following code:\n",
        "\n",
        "num_servers = servers\n",
        "arrival_rate =aver_at\n",
        "\n",
        "def service_level(num_servers, arrival_rate, service_time, iterations=10000, target=5):\n",
        "    completed_jobs = 0\n",
        "    total_jobs = 0\n",
        "    for i in range(iterations):\n",
        "        total_jobs += 1\n",
        "        if response_time(num_servers, arrival_rate, service_time) <= target:\n",
        "            completed_jobs += 1\n",
        "    return completed_jobs / total_jobs\n",
        "\n",
        "print(service_level(num_servers, arrival_rate, service_time, iterations=20000, target=5))\n",
        "\n",
        "#This code calculates the service level for a target of 90% within 5 minutes using 10,000 iterations of the simulation. \n",
        "#The output is the percentage of jobs that were completed within the target time frame.\n"
      ],
      "metadata": {
        "id": "ddDxvZHQibXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8.Cost\n",
        "This metric measures the total cost of operating the queuing system, including the cost of servers, infrastructure, and staffing. It is an important metric for evaluating the profitability of the system\n"
      ],
      "metadata": {
        "id": "L_zX4Lm120Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define system parameters which are already pre_deterined\n",
        "num_servers = servers\n",
        "arrival_rate = aver_at\n",
        "service_time_mean = avg_serv_t\n",
        "\n",
        "# Define costs all are current prices at 2023\n",
        "server_cost = 136.58 # in unit cost of United States Dollar\n",
        "job_cost = 500 #in unit cost of United States Dollar\n",
        "wait_cost = 4 # in melbourne parking fee currently United States Dollar per hour\n",
        "\n",
        "# Simulate the queuing model\n",
        "time_frame = 60 # minutes in 1 hour\n",
        "total_jobs = arrival_rate * time_frame\n",
        "utilization_rate = arrival_rate * service_time_mean / num_servers\n",
        "avg_jobs = utilization_rate / (1 - utilization_rate)\n",
        "avg_waiting_time = avg_jobs / arrival_rate\n",
        "avg_response_time = service_time_mean / (1 - utilization_rate)\n",
        "server_cost_total = server_cost * num_servers * time_frame\n",
        "job_cost_total = job_cost * total_jobs\n",
        "wait_cost_total = wait_cost * avg_waiting_time * total_jobs\n",
        "total_cost = server_cost_total + job_cost_total + wait_cost_total\n",
        "\n",
        "# Print the results\n",
        "print(f\"Total cost in dollars: {total_cost}\")\n"
      ],
      "metadata": {
        "id": "hGSJcRIS3SRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysing the queue model/distribution of the model"
      ],
      "metadata": {
        "id": "sgFUJFEExQvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine the distribution of a multiserver queuing model for over 1000 servers using Python, you will need to perform some statistical analysis on the data. Here are the steps you can follow:\n",
        "\n",
        "* Collect data: Collect data on the arrival rate, service rate, and the number of servers in the system. You can use simulations or real-world data to collect this information.\n",
        "\n",
        "* Analyze the data: Use statistical software in Python such as NumPy, SciPy, and Pandas to analyze the data. Calculate the mean, variance, and standard deviation of the data.\n",
        "\n",
        "* Choose a distribution: Once you have analyzed the data, choose a probability distribution that best fits the data. There are several probability distributions to choose from, such as the Poisson distribution, the exponential distribution, or the normal distribution.\n",
        "\n",
        "* Fit the distribution: Use the chosen probability distribution to fit the data. You can use Python libraries such as SciPy or Statsmodels to fit the distribution.\n",
        "\n",
        "* Evaluate the model: Evaluate the goodness of fit of the model using statistical tests such as the Kolmogorov-Smirnov test or the Chi-Square test.\n",
        "\n",
        "* Interpret the results: Once you have a model that fits the data well, you can use it to make predictions about the queuing system. You can use the model to estimate the average waiting time, the utilization rate of the servers, and other performance metrics.\n",
        "\n",
        "\n",
        "Overall, analyzing a multiserver queuing model for over 1000 servers using Python can be complex and time-consuming. It may be useful to consult with a statistician or an expert in queuing theory to ensure that your analysis is accurate and reliable."
      ],
      "metadata": {
        "id": "lzLnlyw4BN9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the queuing model\n",
        "arrival_rate = 5  # customers per minute\n",
        "service_rate = 6  # customers per minute\n",
        "num_servers = 1000\n",
        "\n",
        "# Generate random arrivals and service times\n",
        "arrival_times = np.cumsum(np.random.exponential(scale=1/arrival_rate, size=1000))\n",
        "service_times = np.random.exponential(scale=1/service_rate, size=1000)\n",
        "\n",
        "# Simulate the queuing system\n",
        "num_customers = len(arrival_times)\n",
        "servers = np.zeros(num_servers)\n",
        "queue = []\n",
        "wait_times = np.zeros(num_customers)\n",
        "for i in range(num_customers):\n",
        "    # Check for available servers\n",
        "    available_servers = np.where(servers == 0)[0]\n",
        "    if len(available_servers) > 0:\n",
        "        # Assign customer to a server\n",
        "        server_index = available_servers[0]\n",
        "        servers[server_index] = service_times[i]\n",
        "        wait_times[i] = 0\n",
        "    else:\n",
        "        # Add customer to queue\n",
        "        queue.append(i)\n",
        "        wait_times[i] = arrival_times[i] - arrival_times[queue[0]]\n",
        "    \n",
        "    # Update server times\n",
        "    servers -= np.minimum(servers, arrival_times[i+1] - arrival_times[i])\n",
        "    \n",
        "    # Check if any customers have finished service\n",
        "    finished_customers = np.where(servers == 0)[0]\n",
        "    for j in finished_customers:\n",
        "        if len(queue) > 0:\n",
        "            # Assign customer from queue to server\n",
        "            queue_index = queue.pop(0)\n",
        "            servers[j] = service_times[queue_index]\n",
        "            wait_times[queue_index] = arrival_times[queue_index] - arrival_times[queue[0]]\n",
        "            \n",
        "# Collect statistics\n",
        "average_waiting_time = np.mean(wait_times)\n",
        "average_queue_length = np.mean([len(queue) for i in range(num_customers)])\n",
        "utilization = np.mean(servers > 0)\n",
        "\n",
        "# Analyze the results\n",
        "# You can use libraries such as matplotlib and seaborn to create histogram plots and density plots of the wait times and queue lengths.\n"
      ],
      "metadata": {
        "id": "H9-aDMiSBRBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating inter arrival times using exponential distribution\n",
        "inter_arrival_times = list(np.random.exponential(scale=1/l,size=ncust))\n",
        "\n",
        "    #plotting data\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.distplot(inter_arrival_times,kde=False,color='r',bins=20)\n",
        "plt.title('Time between Arrivals')\n",
        "plt.xlabel('Minutes')\n",
        "plt.ylabel('Frequency')\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        " # Generate random service times for each customer \n",
        "service_times = list(np.random.exponential(scale=1/µ,size=ncust))  \n",
        "\n",
        "#service time distribution plot\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.distplot(service_times,kde=False,bins=20)\n",
        "plt.title('Service Times')\n",
        "plt.xlabel('Minutes')\n",
        "plt.ylabel('Frequency')\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lMJgEQtyBh1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import simpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define parameters of the queuing model\n",
        "arrival_rate = 10.0  # customers per second\n",
        "service_rate = 1.0   # seconds per customer\n",
        "num_servers = 1000\n",
        "\n",
        "# Define function to simulate customer arrivals\n",
        "def customer_arrivals(env, arrival_rate):\n",
        "    i = 0\n",
        "    while True:\n",
        "        yield env.timeout(np.random.exponential(1/arrival_rate))\n",
        "        i += 1\n",
        "        env.process(customer(env, i))\n",
        "\n",
        "# Define function to simulate customer service\n",
        "def customer(env, id):\n",
        "    with server.request() as req:\n",
        "        yield req\n",
        "        service_time = np.random.exponential(service_rate)\n",
        "        yield env.timeout(service_time)\n",
        "        total_time = env.now - start_time\n",
        "        queuing_times.append(total_time - service_time)\n",
        "\n",
        "# Create the simulation environment\n",
        "env = simpy.Environment()\n",
        "server = simpy.Resource(env, capacity=num_servers)\n",
        "queuing_times = []\n",
        "start_time = env.now\n",
        "\n",
        "# Start the simulation\n",
        "env.process(customer_arrivals(env, arrival_rate))\n",
        "env.run(until=1000)\n",
        "\n",
        "# Analyze the results\n",
        "mean_time = np.mean(queuing_times)\n",
        "std_time = np.std(queuing_times)\n",
        "plt.hist(queuing_times, bins=50)\n",
        "plt.xlabel('Queuing Time')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(f'Distribution of Queuing Times (mean={mean_time:.2f}, std={std_time:.2f})')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xhhtPvmdBjwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering of the Markov Chain Model"
      ],
      "metadata": {
        "id": "rpAsYnnttKKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.State\n",
        "The state of a Markov chain is the current position of the system. In the case of parking availability, the state could be \"full\", \"half-full\", or \"empty\"."
      ],
      "metadata": {
        "id": "v7vP61j7xwTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataq.head(1)"
      ],
      "metadata": {
        "id": "7hd44ncn9Rdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the data\n",
        "data=dataq\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Encode the categorical column\n",
        "data[\"VehiclePresent\"] = encoder.fit_transform(data[\"VehiclePresent\"])"
      ],
      "metadata": {
        "id": "jvPjf3tvERsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(1)"
      ],
      "metadata": {
        "id": "LhqK7Ff-C9dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the occupancy levels\n",
        "FULL = 1.0\n",
        "HALF_FULL = 0.5\n",
        "EMPTY = 0.0\n",
        "\n",
        "# Create a new column for the state\n",
        "data[\"State\"] = data[\"VehiclePresent\"].apply(lambda x: \"Full\" if x >= FULL else \"Half-Full\" if x >= HALF_FULL else \"Empty\")\n",
        "\n",
        "# Print the results\n",
        "data.head(3)"
      ],
      "metadata": {
        "id": "DWLqAI3UE1No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Transition matrix/Transition Probabilities\n",
        " The transition matrix is a table that shows the probability of moving from one state to another. In the case of parking availability, the transition matrix could show the probability of a parking lot going from \"full\" to \"half-full\" or from \"half-full\" to \"empty\".We will calculate the transition probabilities between states for each AreaName. These probabilities represent the likelihood of moving from one occupancy state to another (e.g., full to half-full, half-full to empty) within each AreaName."
      ],
      "metadata": {
        "id": "mTODNRVHyJs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column for the previous occupancy level\n",
        "data[\"Previous_Occupancy\"] = data[\"State\"].shift(1)\n",
        "\n",
        "# Create a new column for the transition probability\n",
        "data[\"Transition_Probability\"] = data[\"State\"].eq(data[\"Previous_Occupancy\"])\n",
        "\n",
        "# Calculate the transition probability matrix\n",
        "transition_probability_matrix = data.groupby(\"AreaName\")[\"Transition_Probability\"].mean()\n",
        "\n",
        "# Print the results\n",
        "print(transition_probability_matrix.head(10))"
      ],
      "metadata": {
        "id": "KUsCqNxr1OE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transition probability matrix shows the probability of an AreaName transitioning from one occupancy level to another. \n",
        "\n",
        "For example, the AreaName Chinatown has a 65% probability of transitioning from \"Full\" to \"Full\" and a 35% probability of transitioning from \"Full\" to \"Half-Full\"."
      ],
      "metadata": {
        "id": "Oh90F46TH8T8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.Initial distribution\n",
        "The initial distribution is a probability distribution that represents the initial state of the system. In the case of parking availability, the initial distribution could show the probability that a parking lot is \"full\", \"half-full\", or \"empty\" at the beginning of the day. We calculate the expected or actual time it takes to reach specific occupancy states for the first time, starting from a given initial state. This parameter can help analyze the time required for certain occupancy levels to be reached in each Areaname.\n",
        "We can take state from morning example when its empty to whenit was first occupied."
      ],
      "metadata": {
        "id": "KOs8EtMxySTc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft0rr2gh5uPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.Ergodicity and Reachability\n",
        "This property ensures that all occupancy states can be reached from any other state within a AreaName,ensuring long-term exploration of the state space."
      ],
      "metadata": {
        "id": "4AnmtAwz5u-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the outlier Areaname=docklands from the transition probability matrix\n",
        "transition_probability_matrix= transition_probability_matrix.drop(index=['Docklands'])"
      ],
      "metadata": {
        "id": "JlH-oNOqSr7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the index of the DataFrame if docklands is dropped\n",
        "transition_probability_matrix.index"
      ],
      "metadata": {
        "id": "7VAb8gOTOEUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the transition probability matrix to a NumPy array\n",
        "transition_probability_matrix_numpy = np.array(transition_probability_matrix)"
      ],
      "metadata": {
        "id": "hazMRxBSUXAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add a dimension to the first array\n",
        "transition_probability_matrix_numpy = transition_probability_matrix_numpy[:, np.newaxis]\n",
        "\n",
        "# Concatenate the two arrays\n",
        "transition_probability_matrix_numpy = np.concatenate((transition_probability_matrix_numpy, np.zeros((35,35))), axis=1)\n",
        "\n",
        "# Calculate the eigenvalues and eigenvectors of the NumPy array\n",
        "eigenvalues, eigenvectors = np.linalg.eig(transition_probability_matrix_numpy)\n",
        "\n",
        "# Print the eigenvalues\n",
        "print(eigenvalues)\n"
      ],
      "metadata": {
        "id": "MjXinCveasBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column of zeros to the matrix\n",
        "transition_probability_matrix_numpy = np.hstack((transition_probability_matrix_numpy, np.zeros(69)))\n",
        "\n",
        "# Reshape the NumPy array to a 2-dimensional array\n",
        "transition_probability_matrix_numpy = transition_probability_matrix_numpy.reshape(69, 69)\n",
        "\n",
        "# Calculate the eigenvalues and eigenvectors of the NumPy array\n",
        "eigenvalues, eigenvectors = np.linalg.eig(transition_probability_matrix_numpy)\n",
        "\n",
        "# Print the eigenvalues\n",
        "print(eigenvalues)"
      ],
      "metadata": {
        "id": "erZJUTRiaci2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the NumPy array to a 2-dimensional array\n",
        "transition_probability_matrix_numpy = transition_probability_matrix_numpy.reshape(1, 69)\n",
        "\n",
        "# Calculate the eigenvalues of the NumPy array\n",
        "eigenvalues, eigenvectors = np.linalg.eig(transition_probability_matrix_numpy)\n",
        "\n",
        "# Print the eigenvalues\n",
        "print(eigenvalues)"
      ],
      "metadata": {
        "id": "SvrgubgdaITt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the last element from the array\n",
        "transition_probability_matrix_numpy = transition_probability_matrix_numpy[:-1]\n",
        "# Reshape the NumPy array to a 2-dimensional array\n",
        "transition_probability_matrix_numpy = transition_probability_matrix_numpy.reshape(34,1)"
      ],
      "metadata": {
        "id": "KFxvI5QsVxuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the eigenvalues of the transition probability matrix\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(transition_probability_matrix_numpy)\n",
        "steady_state_vector = np.real(eigenvectors[:, np.isclose(eigenvalues, 1)])\n",
        "\n",
        "# Normalize the steady-state probabilities\n",
        "steady_state_probs = steady_state_vector / np.sum(steady_state_vector)\n"
      ],
      "metadata": {
        "id": "8keO6-gI55XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all of the eigenvalues are less than 1\n",
        "if all(eigenvalue < 1 for eigenvalue in eigenvalues):\n",
        "    print(\"The system is ergodic.\")\n",
        "else:\n",
        "    print(\"The system is not ergodic.\")"
      ],
      "metadata": {
        "id": "8yHvNmegSWYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f you have a non-square transition probability matrix and the goal is to estimate the steady-state probabilities or analyze ergodicity, it is true that you cannot directly compute eigenvalues using standard linear algebra methods. In such cases, it might be more appropriate to focus on alternative methods such as Markov Chain Monte Carlo (MCMC) sampling or other estimation techniques.\n",
        "\n",
        "The purpose of calculating eigenvalues is typically to determine the steady-state probabilities of a Markov chain, where the eigenvector associated with the eigenvalue 1 represents the stationary distribution. However, for non-square transition matrices, this approach is not applicable.\n",
        "\n",
        "Instead, using MCMC methods, you can simulate the Markov chain over multiple iterations, allowing it to converge towards a stationary distribution. By counting the frequency of visits to each state during the simulation, you can estimate the steady-state probabilities.\n",
        "\n",
        "So, in the context of estimating steady-state probabilities or analyzing ergodicity with a non-square transition probability matrix, it would be appropriate to focus on the MCMC-based approach described earlier rather than pursuing eigenvalue calculations."
      ],
      "metadata": {
        "id": "a4G-kJKpcJ2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming transition_prob_matrix is the transition probability matrix\n",
        "num_iterations = 10000\n",
        "num_areanames = transition_probability_matrix_numpy.shape[0]\n",
        "state_counts = np.zeros(num_areanames)\n",
        "current_state = np.random.choice(num_areanames)  # Initialize a random starting state\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "    state_counts[current_state] += 1\n",
        "    transition_probs = transition_probability_matrix_numpy[current_state]\n",
        "    next_state = np.random.choice(num_areanames, p=transition_probs)\n",
        "    current_state = next_state\n",
        "\n",
        "steady_state_probs = state_counts / num_iterations"
      ],
      "metadata": {
        "id": "jg1nueyrcYQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.Occupancy Duration Statistics\n",
        "Analyze the duration of time spent in different occupancy states within each AreaName.The occupancy of the outlier AreaName is the most important feature for predicting the future state of the system. The outlier district has 99% of the occupancy information, so it is important to get this information accurately.\n",
        "\n",
        "In addition to these parameters, I also saw fit to get the following information:\n",
        "\n",
        "**The number of sensors in each district**. This information will help you to identify the districts that are most likely to be accurate.\n",
        "**The occupancy information from the sensors**. This information will help you to train the Markov chain model.\n",
        "**The time of day and day of week**. This information will help you to identify the times when the parking lots are most likely to be full or empty."
      ],
      "metadata": {
        "id": "kIS-PcxX6YfC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s72b3GaU7aBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import simpy\n",
        "\n",
        "class M_M_1:\n",
        "    def __init__(self, env, arrival_rate, service_rate):\n",
        "        self.env = env\n",
        "        self.arrival_rate = arrival_rate\n",
        "        self.service_rate = service_rate\n",
        "        self.server = simpy.Resource(env, capacity=1)\n",
        "        self.queue = simpy.Container(env, init=0, capacity=float('inf'))\n",
        "        self.arrival_process = env.process(self.arrival())\n",
        "        self.service_process = env.process(self.service())\n",
        "        self.waiting_times = []\n",
        "\n",
        "    def arrival(self):\n",
        "        while True:\n",
        "            yield self.env.timeout(1 / self.arrival_rate)\n",
        "            self.queue.put(1)\n",
        "            if self.server.count == 0:\n",
        "                self.service_process.interrupt()\n",
        "\n",
        "    def service(self):\n",
        "        while True:\n",
        "            yield self.queue.get(1)\n",
        "            start = self.env.now\n",
        "            yield self.env.timeout(1 / self.service_rate)\n",
        "            self.waiting_times.append(self.env.now - start)\n",
        "\n"
      ],
      "metadata": {
        "id": "N0Nhh05msCNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can then use this model to simulate an M/M/1 queue:"
      ],
      "metadata": {
        "id": "cURrYxTmsXCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = simpy.Environment()\n",
        "mm1 = M_M_1(env, arrival_rate=5, service_rate=2)\n",
        "env.run(until=100)"
      ],
      "metadata": {
        "id": "VSZrcJeMsYIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example of a Python model for an M/M/1 queue with infinite buffer and FIFO service:"
      ],
      "metadata": {
        "id": "Ja-xwPQDrO_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code uses the SimPy library to simulate the M/M/1 queue.\n",
        "# The server function represents the server and the customer_generator function generates customers\n",
        "# that arrive at the queue according to an exponential distribution. \n",
        "#The arrival_rate and service_rate are set to 2 and 3 respectively, but can be adjusted as needed. \n",
        "#The simulation runs for 100 time units, but this can also be adjusted.\n",
        "\n",
        "import simpy\n",
        "\n",
        "def server(env, service_rate):\n",
        "    while True:\n",
        "        # Wait for a customer to arrive\n",
        "        customer = yield env.timeout(random.expovariate(1/service_rate))\n",
        "        # Service the customer\n",
        "        yield env.timeout(random.expovariate(1/service_rate))\n",
        "\n",
        "def customer_generator(env, arrival_rate, service_rate):\n",
        "    while True:\n",
        "        yield env.timeout(random.expovariate(1/arrival_rate))\n",
        "        env.process(server(env, service_rate))\n",
        "\n",
        "env = simpy.Environment()\n",
        "arrival_rate = 2\n",
        "service_rate = 3\n",
        "env.process(customer_generator(env, arrival_rate, service_rate))\n",
        "env.run(until=100)\n"
      ],
      "metadata": {
        "id": "3LXgX7KhrKKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a sample implementation of an M/M/1 queue model (also known as an \"Erlang-A\" model) with an infinite buffer and first-in-first-out (FIFO) service discipline in Python:"
      ],
      "metadata": {
        "id": "APKAISNmtdGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class MM1Queue:\n",
        "    def __init__(self, arrival_rate, service_rate):\n",
        "        self.arrival_rate = arrival_rate\n",
        "        self.service_rate = service_rate\n",
        "        self.queue = []\n",
        "        self.time = 0\n",
        "        self.events = []\n",
        "\n",
        "    def simulate(self, end_time):\n",
        "        self.events = [(0, 'arrival')]\n",
        "        while self.time < end_time:\n",
        "            next_event = min(self.events, key=lambda x: x[0])\n",
        "            self.time = next_event[0]\n",
        "            if next_event[1] == 'arrival':\n",
        "                self.handle_arrival()\n",
        "            elif next_event[1] == 'departure':\n",
        "                self.handle_departure()\n",
        "            self.events.remove(next_event)\n",
        "\n",
        "    def handle_arrival(self):\n",
        "        arrival_time = self.time + random.expovariate(self.arrival_rate)\n",
        "        self.events.append((arrival_time, 'arrival'))\n",
        "        if not self.queue:\n",
        "            departure_time = self.time + random.expovariate(self.service_rate)\n",
        "            self.events.append((departure_time, 'departure'))\n",
        "        self.queue.append(arrival_time)\n",
        "\n",
        "    def handle_departure(self):\n",
        "        self.queue.pop(0)\n",
        "        if self.queue:\n",
        "            departure_time = self.time + random.expovariate(self.service_rate)\n",
        "            self.events.append((departure_time, 'departure'))\n"
      ],
      "metadata": {
        "id": "QjWg2jc8tcBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model can be used by creating an instance of the MM1Queue class, setting the arrival rate and service rate, and then running the simulate method to run the simulation for a certain amount of time. For example:"
      ],
      "metadata": {
        "id": "qcTLdYrztiwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queue = MM1Queue(arrival_rate=5, service_rate=10)\n",
        "queue.simulate(end_time=1000)\n"
      ],
      "metadata": {
        "id": "7_vJ8xuLtppx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will simulate an M/M/1 queue with an arrival rate of 5 customers per time unit and a service rate of 10 customers per time unit for 1000 time units.\n",
        "\n",
        "Note that this is a simple example that does not include any statistics gathering or reporting, you can use the queue and events list to gather the relevant statistics you want after the simulation is done.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SadOJzANttPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example implementation of the M/M/1 queuing model in Python for parking prediction:"
      ],
      "metadata": {
        "id": "dCmX6_m9wSrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def mm1_model(arrival_rate, service_rate, capacity):\n",
        "    # Calculate the utilization factor\n",
        "    utilization = arrival_rate / service_rate\n",
        "    \n",
        "    # Calculate the probability of zero customers in the system\n",
        "    p0 = 1 - utilization\n",
        "    \n",
        "    # Calculate the average number of customers in the system\n",
        "    l = utilization / (1 - utilization)\n",
        "    \n",
        "    # Calculate the average waiting time in the system\n",
        "    w = l / arrival_rate\n",
        "    \n",
        "    # Calculate the probability of waiting in the system\n",
        "    p_w = utilization\n",
        "    \n",
        "    # Calculate the probability of blocking\n",
        "    p_block = math.pow(utilization, capacity) * p0\n",
        "    \n",
        "    # Return the results\n",
        "    return l, w, p_w, p_block\n"
      ],
      "metadata": {
        "id": "HtnpPCXUwanf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes three input parameters: the arrival rate (in customers per unit of time), the service rate (in customers per unit of time), and the capacity of the parking lot (the number of parking spots available). It returns four output parameters: the average number of customers in the system, the average waiting time in the system, the probability of waiting in the system, and the probability of blocking (i.e., the probability that all parking spots are occupied).\n",
        "\n",
        "To use this function, you would first need to estimate the arrival rate and service rate based on historical data or other sources of information. You would also need to determine the capacity of the parking lot. Then you could call the function like this:"
      ],
      "metadata": {
        "id": "ljCfekppwihq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arrival_rate = 10 # customers per minute\n",
        "service_rate = 12 # customers per minute\n",
        "capacity = 50 # parking spots\n",
        "l, w, p_w, p_block = mm1_model(arrival_rate, service_rate, capacity)\n",
        "print(\"Average number of customers in the system: \", l)\n",
        "print(\"Average waiting time in the system: \", w)\n",
        "print(\"Probability of waiting in the system: \", p_w)\n",
        "print(\"Probability of blocking: \", p_block)\n"
      ],
      "metadata": {
        "id": "6azY-8xsw2a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# M/M/M MODEL\n"
      ],
      "metadata": {
        "id": "bh08FVDDGhjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement the M/M/M queuing model for parking prediction in Python, we can use the simpy package, which is a discrete-event simulation framework. Here is an example code:"
      ],
      "metadata": {
        "id": "qryDMPM_GmbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SimPy"
      ],
      "metadata": {
        "id": "ojJ7M4kDTFu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import simpy\n",
        "import numpy as np\n",
        "\n",
        "arrival_rate=aver_at\n",
        "service_rate=avg_serv_t\n",
        "\n",
        "class ParkingLot:\n",
        "    def __init__(self, env, n, m, arrival_rate, service_rate):\n",
        "        self.env = env\n",
        "        self.n = n\n",
        "        self.m = m\n",
        "        self.arrival_rate = arrival_rate\n",
        "        self.service_rate = service_rate\n",
        "        self.parking_spaces = simpy.Resource(env, capacity=n)\n",
        "        self.waiting_times = []\n",
        "\n",
        "    def park_car(self):\n",
        "        with self.parking_spaces.request() as req:\n",
        "            yield req\n",
        "            waiting_time = self.env.now - self.arrival_time\n",
        "            self.waiting_times.append(waiting_time)\n",
        "            service_time = np.random.exponential(1/self.service_rate)\n",
        "            yield self.env.timeout(service_time)\n",
        "\n",
        "    def run(self, run_time):\n",
        "        self.env.process(self.generate_cars())\n",
        "        self.env.run(until=run_time)\n",
        "\n",
        "    def generate_cars(self):\n",
        "        while True:\n",
        "            inter_arrival_time = np.random.exponential(1/self.arrival_rate)\n",
        "            yield self.env.timeout(inter_arrival_time)\n",
        "            self.arrival_time = self.env.now\n",
        "            self.env.process(self.park_car())\n",
        "\n",
        "    def occupancy(self):\n",
        "        return (self.n - len(self.parking_spaces.queue)) / self.n\n",
        "\n",
        "    def utilization(self):\n",
        "        return sum([len(x) for x in self.parking_spaces.users])/self.m\n",
        "\n",
        "    def average_waiting_time(self):\n",
        "        return np.mean(self.waiting_times)\n",
        "\n",
        "    def probability_of_waiting(self):\n",
        "        return len([x for x in self.waiting_times if x > 0])/len(self.waiting_times)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Y9SWvdaG6Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import simpy\n",
        "import numpy as np\n",
        "\n",
        "class ParkingLot:\n",
        "    # define the ParkingLot class (code omitted for brevity)\n",
        "\n",
        "# create a simulation environment\n",
        " env = simpy.Environment()\n",
        "\n",
        "# set the simulation parameters\n",
        "n = 20 # number of parking spaces\n",
        "m = 2 # number of attendants\n",
        "arrival_rate = 5 # average number of cars arriving per hour\n",
        "service_rate = 10 # average time to service a car in minutes\n",
        "\n",
        "# create an instance of the ParkingLot class\n",
        "parking_lot = ParkingLot(env, n, m, arrival_rate/60, service_rate)\n",
        "\n",
        "# run the simulation for 8 hours\n",
        "parking_lot.run(run_time=8*60)\n",
        "\n",
        "# analyze the results\n",
        "print(f\"Occupancy: {parking_lot.occupancy():.2%}\")\n",
        "print(f\"Utilization: {parking_lot.utilization():.2%}\")\n",
        "print(f\"Average waiting time: {parking_lot.average_waiting_time():.2f} minutes\")\n",
        "print(f\"Probability of waiting: {parking_lot.probability_of_waiting():.2%}\")\n"
      ],
      "metadata": {
        "id": "SAqapY-GYQZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we define a ParkingLot class that simulates the queuing system. The __init__ method initializes the parameters of the model, such as the number of parking spaces n, the number of servers m, the arrival rate arrival_rate, and the service rate service_rate. It also creates a simpy.Resource object that represents the parking spaces.\n",
        "\n",
        "The park_car method simulates the process of parking a car. It requests a parking space from the simpy.Resource object, calculates the waiting time, and generates a service time from an exponential distribution with mean 1/service_rate.\n",
        "\n",
        "The run method starts the simulation and runs it for a specified time run_time. The generate_cars method generates cars according to a Poisson process with rate arrival_rate, and for each car, it calls the park_car method as a subprocess.\n",
        "\n",
        "The occupancy method calculates the occupancy rate of the parking lot, which is the proportion of occupied parking spaces. The utilization method calculates the utilization rate of the servers, which is the proportion of time they are busy. The average_waiting_time method calculates the average waiting time of customers who had to wait. The probability_of_waiting method calculates the probability that a customer has to wait.\n",
        "\n",
        "To use the ParkingLot class, we can create an instance with the desired parameters and run the simulation:"
      ],
      "metadata": {
        "id": "A4Xq-qlgG-Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50  # number of parking spaces\n",
        "m = 3   # number of servers\n",
        "arrival_rate = 2  # customers per minute\n",
        "service_rate = 3  # customers per minute\n",
        "\n",
        "env = simpy.Environment()\n",
        "parking_lot = ParkingLot(env, n, m, arrival_rate, service_rate)\n",
        "parking_lot.run(120)  # run simulation for 60 minutes\n",
        "\n",
        "#print(\"Occupancy rate:\", parking_lot)\n"
      ],
      "metadata": {
        "id": "CAA3O4mPGu9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example implementation of the M/M/M queuing model for parking prediction in Python, using the numpy and scipy libraries for scientific computing:"
      ],
      "metadata": {
        "id": "hzpQkTaR_Q9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import poisson, expon\n",
        "\n",
        "def parking_mmm_model(n, m, lambda_, mu):\n",
        "    \"\"\"M/M/M queuing model for parking prediction\"\"\"\n",
        "    \n",
        "    # Calculate utilization rate\n",
        "    rho = lambda_ / (m * mu)\n",
        "    \n",
        "    # Calculate expected number of customers in system\n",
        "    num_customers = (rho ** n) * ((1 - rho) / (1 - rho ** (n + 1)))\n",
        "    \n",
        "    # Calculate expected waiting time\n",
        "    wait_time = num_customers / (lambda_ * (1 - rho))\n",
        "    \n",
        "    # Calculate probability of waiting\n",
        "    prob_wait = rho ** n * (1 - rho) / (1 - rho ** (n + 1))\n",
        "    \n",
        "    # Calculate probability of all spaces occupied\n",
        "    prob_full = rho ** n\n",
        "    \n",
        "    return num_customers, wait_time, prob_wait, prob_full\n",
        "\n",
        "# Example usage\n",
        "n = 1000000 # number of parking spaces\n",
        "m = servers  # number of servers\n",
        "lambda_ = aver_at  # arrival rate (per minute)\n",
        "mu = avg_serv_t  # service rate (per minute)\n",
        "\n",
        "num_customers, wait_time, prob_wait, prob_full = parking_mmm_model(n, m, lambda_, mu)\n",
        "\n",
        "print(f\"Expected number of customers in system: {num_customers:.2f}\")\n",
        "print(f\"Expected waiting time: {wait_time:.2f} mins\")\n",
        "print(f\"Probability of waiting: {prob_wait:.2f}\")\n",
        "print(f\"Probability of all spaces occupied: {prob_full:.2f}\")\n"
      ],
      "metadata": {
        "id": "eSYrzK6c_PBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function parking_mmm_model that takes as input the number of parking spaces n, the number of servers m, the arrival rate lambda_, and the service rate mu, and returns the expected number of customers in the system, the expected waiting time, the probability of waiting, and the probability of all parking spaces being occupied.\n",
        "\n",
        "The function first calculates the utilization rate rho, which is the key parameter in the M/M/M queuing model. It then uses this parameter to calculate the expected number of customers in the system, the expected waiting time, and the probabilities of waiting and all spaces being occupied.\n",
        "\n",
        "The example usage section shows how to call the function with some sample inputs, and prints the results. Note that the expected waiting time is in hours, since the arrival rate and service rate are specified in units of customers per hour."
      ],
      "metadata": {
        "id": "3C4bPED0_VrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here's an updated version of the M/M/M parking prediction model in Python where the number of servers is set to 1100:"
      ],
      "metadata": {
        "id": "Apb-zZX4_4Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import poisson, expon\n",
        "\n",
        "def parking_mmm_model(n, m, lambda_, mu):\n",
        "    \"\"\"M/M/M queuing model for parking prediction\"\"\"\n",
        "    \n",
        "    # Calculate utilization rate\n",
        "    rho = lambda_ / (m * mu)\n",
        "    \n",
        "    # Calculate expected number of customers in system\n",
        "    num_customers = (rho ** n) * ((1 - rho) / (1 - rho ** (n + 1)))\n",
        "    \n",
        "    # Calculate expected waiting time\n",
        "    wait_time = num_customers / (lambda_ * (1 - rho))\n",
        "    \n",
        "    # Calculate probability of waiting\n",
        "    prob_wait = rho ** n * (1 - rho) / (1 - rho ** (n + 1))\n",
        "    \n",
        "    # Calculate probability of all spaces occupied\n",
        "    prob_full = rho ** n\n",
        "    \n",
        "    return num_customers, wait_time, prob_wait, prob_full\n",
        "\n",
        "# Example usage with 1100 servers\n",
        "n = 100  # number of parking spaces\n",
        "m = 1100  # number of servers\n",
        "lambda_ = 2  # arrival rate (per hour)\n",
        "mu = 3  # service rate (per hour)\n",
        "\n",
        "num_customers, wait_time, prob_wait, prob_full = parking_mmm_model(n, m, lambda_, mu)\n",
        "\n",
        "print(f\"Expected number of customers in system: {num_customers:.2f}\")\n",
        "print(f\"Expected waiting time: {wait_time:.2f} hours\")\n",
        "print(f\"Probability of waiting: {prob_wait:.2f}\")\n",
        "print(f\"Probability of all spaces occupied: {prob_full:.2f}\")\n"
      ],
      "metadata": {
        "id": "-5iudHRx_12y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only change is to set the m parameter to 1100 instead of 3. The other inputs (number of parking spaces, arrival rate, and service rate) are the same as in the previous example.\n",
        "\n",
        "Note that with 1100 servers, the utilization rate will likely be very low (unless the arrival rate is extremely high), which means that the parking lot will be highly underutilized. In practice, it is unlikely that a parking lot would have 1100 servers (i.e., parking attendants) for only 100 parking spaces."
      ],
      "metadata": {
        "id": "opHaYwUZ__8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bayesian model"
      ],
      "metadata": {
        "id": "lrSerIh6_zTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Prior distribution\n",
        " A non-informative prior distribution, such as a uniform distribution, would be appropriate for this data. This is because we do not have any prior information about the occupancy levels in the Areanames.\n",
        " We have used beta distribution instead\n"
      ],
      "metadata": {
        "id": "yABYS6qGAtIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "alpha = 2\n",
        "beta = 2\n",
        "\n",
        "outlier_occupancy_prior = np.random.beta(alpha, beta)\n",
        "occupancy_rates_prior = np.random.beta(alpha, beta, size=35)\n",
        "sensor_reliability_prior = np.random.beta(alpha, beta)\n",
        "transition_probs_prior = np.random.dirichlet(alpha=[0.5, 0.5, 0.5])  # assume all areanames have the same 3 states\n"
      ],
      "metadata": {
        "id": "1R7M9Kd1IXqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Likelihood function \n",
        "The likelihood function should be based on the observed data. In this case, the likelihood function would be the probability of observing the data that we did, given the parameters of the model."
      ],
      "metadata": {
        "id": "NjaZtJwUA0d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the discrete random variable also\n",
        "# Define the likelihood function\n",
        "likelihood_function = stats.poisson(1)"
      ],
      "metadata": {
        "id": "Y_r6mVAfBQX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "def likelihood(outlier_occupancy, occupancy_rates, sensor_reliability, transition_probs):\n",
        "    # Compute the likelihood based on the model parameters and the observed data\n",
        "    # For example, if you have occupancy_data and sensor_data:\n",
        "    likelihood = binom.pmf(sensor_data, occupancy_data, sensor_reliability)\n",
        "    return likelihood"
      ],
      "metadata": {
        "id": "IW6HgyTtJII2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.Posterior distribution\n",
        "The posterior distribution is the probability of the parameters of the model, given the observed data. The posterior distribution can be calculated using Bayes' theorem."
      ],
      "metadata": {
        "id": "2E9nBzhmBBXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "MPg46mVpFMnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the posterior distribution\n",
        "posterior_distribution =(transition_probs_prior*likelihood_function(data[\"VehiclePresent\"]))\n",
        "\n",
        "# Print the posterior distribution"
      ],
      "metadata": {
        "id": "9bCWInJOBRC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymc3"
      ],
      "metadata": {
        "id": "_lGVcRroKb6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc3 as pm\n",
        "\n",
        "# Define the Bayesian model\n",
        "with pm.Model() as model:\n",
        "    # Priors for the parameters\n",
        "    outlier_occupancy = pm.Beta('outlier_occupancy', alpha, beta)\n",
        "    occupancy_rates = pm.Beta('occupancy_rates', alpha, beta, shape=35)\n",
        "    sensor_reliability = pm.Beta('sensor_reliability', alpha, beta)\n",
        "    transition_probs = pm.Dirichlet('transition_probs', alpha=[0.5, 0.5, 0.5])  # Example with 3 states\n",
        "\n",
        "    # Likelihood function\n",
        "    likelihood = pm.Binomial('likelihood', n=sensor_data, p=sensor_reliability, observed=occupancy_data)\n",
        "\n",
        "    # Perform MCMC sampling\n",
        "    trace = pm.sample(1000, tune=500)\n"
      ],
      "metadata": {
        "id": "1kg4PGVYJ-tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiple linear regression\n"
      ],
      "metadata": {
        "id": "Mudm-uTv0c2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python code to demonstrate how multiple linear regression can be used to predict parking occupancy based on external factors:\n",
        "\n",
        "\n",
        "In this example, we first load the parking occupancy data and external factors data, and then merge them based on the date column. We then split the merged data into training and testing sets, and define the independent variables (weather, time of day, day of week, and holiday) and dependent variable (occupancy).\n",
        "\n",
        "Next, we create a multiple linear regression model using scikit-learn's LinearRegression class, and fit it to the training data. We then use the trained model to predict the parking occupancy for the test data, and evaluate the accuracy of the model using mean squared error."
      ],
      "metadata": {
        "id": "QvF7axkk05F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the parking occupancy and external factors data\n",
        "parking_data = pd.read_csv('parking_data.csv')\n",
        "external_factors = pd.read_csv('external_factors.csv')\n",
        "\n",
        "# Merge the parking occupancy and external factors data\n",
        "merged_data = pd.merge(parking_data, external_factors, on='date')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = merged_data.loc[merged_data['date'] < '2022-01-01']\n",
        "test_data = merged_data.loc[merged_data['date'] >= '2022-01-01']\n",
        "\n",
        "# Define the independent variables and dependent variable\n",
        "X_train = train_data[['weather', 'time_of_day', 'day_of_week', 'holiday']]\n",
        "y_train = train_data['occupancy']\n",
        "\n",
        "X_test = test_data[['weather', 'time_of_day', 'day_of_week', 'holiday']]\n",
        "y_test = test_data['occupancy']\n",
        "\n",
        "# Create a multiple linear regression model and fit it to the training data\n",
        "reg_model = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# Use the trained model to predict the parking occupancy for the test data\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model using mean squared error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean squared error: {mse}\")\n"
      ],
      "metadata": {
        "id": "P3jhxgDg0qVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# autoregressive integrated moving average (ARIMA)\n",
        "\n",
        "demonstrate how the ARIMA model can be used to forecast future parking occupancy based on historical occupancy data:"
      ],
      "metadata": {
        "id": "3GmmG3hW1hPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first load the historical parking occupancy data and convert the date column to a datetime object and set it as the index. We then split the data into training and testing sets.\n",
        "\n",
        "Next, we create an ARIMA model using the statsmodels library's ARIMA class, with the order parameter set to (2, 1, 1) to specify an ARIMA(2,1,1) model. We then fit the ARIMA model to the training data.\n",
        "\n",
        "We use the ARIMA model to forecast the parking occupancy for the test data using the forecast method. Finally, we evaluate the accuracy of the model using mean squared error."
      ],
      "metadata": {
        "id": "D0Aiubwi16hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we then check if our arrival times are stationary\n",
        "#to check stationarity we draw a scatter plot of cumulative customers(y-axis)\n",
        "#and that of cumulative arrival times(x-axis)"
      ],
      "metadata": {
        "id": "MXvFWM9WkBeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Load the historical parking occupancy data\n",
        "#parking_data = pd.read_csv('parking_data.csv')\n",
        "\n",
        "# Convert the date column to a datetime object and set it as the index\n",
        "dataq['Day'] = pd.to_datetime(dataq['Day'])\n",
        "datak= dataq.set_index('Day')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = dataq.loc[datak.index < '1']\n",
        "test_data = dataq.loc[datak.index >= '7']\n",
        "\n",
        "# Create an ARIMA model and fit it to the training data\n",
        "arima_model = ARIMA(train_data, order=(2, 1, 1)).fit()\n",
        "\n",
        "# Use the ARIMA model to forecast the parking occupancy for the test data\n",
        "forecast_data = arima_model.forecast(steps=len(test_data))\n",
        "\n",
        "# Evaluate the accuracy of the model using mean squared error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(test_data, forecast_data)\n",
        "print(f\"Mean squared error: {mse}\")\n"
      ],
      "metadata": {
        "id": "ecLxYSPJ1lwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first load the parking occupancy data and convert the date column to datetime format and set it as the index. We then split the data into training and testing sets.\n",
        "\n",
        "Next, we fit an ARIMA model to the training data using statsmodels' ARIMA class with an order of (1, 1, 1), which specifies an autoregressive model of order 1, a differencing of order 1, and a moving average model of order 1.\n",
        "\n",
        "We then use the fitted model to forecast the parking occupancy for the test data using the forecast method, which returns an array of predicted values.\n",
        "\n",
        "Finally, we plot the predicted and actual occupancy values for the test data using matplotlib."
      ],
      "metadata": {
        "id": "ixqxj9FT2ORZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the parking occupancy and external factors data\n",
        "parking_data = pd.read_csv('parking_data.csv')\n",
        "external_factors = pd.read_csv('external_factors.csv')\n",
        "\n",
        "# Merge the parking occupancy and external factors data\n",
        "merged_data = pd.merge(parking_data, external_factors, on='date')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = merged_data.loc[merged_data['date'] < '2022-01-01']\n",
        "test_data = merged_data.loc[merged_data['date'] >= '2022-01-01']\n",
        "\n",
        "# Define the independent variables and dependent variable\n",
        "X_train = train_data[['weather', 'time_of_day', 'day_of_week', 'holiday']]\n",
        "y_train = train_data['occupancy']\n",
        "\n",
        "X_test = test_data[['weather', 'time_of_day', 'day_of_week', 'holiday']]\n",
        "y_test = test_data['occupancy']\n",
        "\n",
        "# Create a multiple linear regression model and fit it to the training data\n",
        "reg_model = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# Use the trained model to predict the parking occupancy for the test data\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model using mean squared error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean squared error: {mse}\")\n"
      ],
      "metadata": {
        "id": "62aQBmXA2OuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deep learning:LSTM Model and  cnn "
      ],
      "metadata": {
        "id": "us340FN43E8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First, let's import the necessary libraries:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "Vy4WRTnN3Mwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, let's load the parking availability data and preprocess it:\n",
        "# Load the parking availability data\n",
        "data = pd.read_csv('parking_data.csv')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = data[:8000]\n",
        "test_data = data[8000:]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "test_data_scaled = scaler.transform(test_data)\n"
      ],
      "metadata": {
        "id": "H7SgCWAP3Uv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let's define the LSTM model:\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(train_data_scaled.shape[1], 1)))\n",
        "lstm_model.add(LSTM(units=50))\n",
        "lstm_model.add(Dense(units=1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "K8onhtS33e4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, let's train the LSTM model:\n",
        "# Train the LSTM model\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, len(train_data_scaled)):\n",
        "    X_train.append(train_data_scaled[i-60:i, 0])\n",
        "    y_train.append(train_data_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "id": "Twh3u_7U3mMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let's define the CNN model:\n",
        "# Define the CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(train_data_scaled.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(units=1))\n",
        "cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "xgAa0-Jf3x_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, let's train the CNN model:\n",
        "# Train the CNN model\n",
        "X_train_cnn = []\n",
        "y_train_cnn = []\n",
        "for i in range(60, len(train_data_scaled)):\n",
        "    X_train_cnn.append(train_data_scaled[i-60:i, 0])\n",
        "    y_train_cnn.append(train_data_scaled[i, 0])\n",
        "X_train_cnn, y_train_cnn = np.array(X_train_cnn), np.array(y_train_cnn)\n",
        "X_train_cnn = np.reshape(X_train_cnn, (X_train_cnn.shape[0], X_train_cnn.shape[1], 1))\n",
        "cnn_model.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=32)\n"
      ],
      "metadata": {
        "id": "dsJvov5V37NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, let's use the trained models to predict parking availability:\n",
        "# Predict parking availability using the LSTM model\n",
        "X_test = []\n",
        "for i in range(60, len(test_data_scaled)):\n",
        "    X_test.append(test_data_scaled[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n"
      ],
      "metadata": {
        "id": "B6xHAGE54B-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "how you can use LSTM and CNN models for parking availability prediction based on the study by Ma et al. (2021). Please note that this code is for illustration purposes only and may require modification based on your specific data and requirements.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p3PRSPtU4xVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the parking data\n",
        "df = pd.read_csv('parking_data.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df['parking_availability'].values.reshape(-1, 1))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(scaled_data) * 0.8)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train_data = scaled_data[0:train_size, :]\n",
        "test_data = scaled_data[train_size:len(scaled_data), :]\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(1, 1)))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(LSTM(units=50))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(Dense(units=1))\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "lstm_model.fit(train_data, epochs=100, batch_size=32)\n",
        "\n",
        "# Define the CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, 1)))\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(50, activation='relu'))\n",
        "cnn_model.add(Dense(1))\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "cnn_model.fit(train_data, epochs=100, batch_size=32)\n",
        "\n",
        "# Predict parking availability using the trained models\n",
        "lstm_predictions = lstm_model.predict(test_data)\n",
        "lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
        "cnn_predictions = cnn_model.predict(test_data)\n",
        "cnn_predictions = scaler.inverse_transform(cnn_predictions)\n",
        "\n",
        "# Evaluate the models\n",
        "lstm_rmse = np.sqrt(np.mean(np.power((test_data - lstm_predictions), 2)))\n",
        "cnn_rmse = np.sqrt(np.mean(np.power((test_data - cnn_predictions), 2)))\n",
        "\n",
        "print(\"LSTM RMSE: \", lstm_rmse)\n",
        "print(\"CNN RMSE: \", cnn_rmse)\n"
      ],
      "metadata": {
        "id": "i9HYOq9y4u2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code assumes that you have a CSV file containing the parking availability data and the column name for parking availability data is 'parking_availability'. You can replace the filename and column name in the code with your own data.\n",
        "\n",
        "The code uses the MinMaxScaler to normalize the data and split it into training and testing sets. It then defines the LSTM and CNN models and trains them using the training data. Finally, it uses the trained models to predict parking availability for the test data and evaluates the models using the root mean squared error (RMSE)."
      ],
      "metadata": {
        "id": "WtaW9SLy46Op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Regression (SVR) model for prediction "
      ],
      "metadata": {
        "id": "xE6hXMx55ZOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVR model\n",
        "svr_model = SVR(kernel='linear', C=1.0, epsilon=0.2)\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable for the test data\n",
        "y_pred = svr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: \", rmse)\n"
      ],
      "metadata": {
        "id": "F5hdq3mZ5aO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the parking data\n",
        "df = dataq\n",
        "\n",
        "# Preprocess the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df['VehiclePresent'].values.reshape(-1, 1))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(len(scaled_data) * 0.8)\n",
        "test_size = len(scaled_data) - train_size\n",
        "train_data = scaled_data[0:train_size, :]\n",
        "test_data = scaled_data[train_size:len(scaled_data), :]\n",
        "\n",
        "# Define the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(1, 1)))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(LSTM(units=50))\n",
        "lstm_model.add(Dropout(0.2))\n",
        "lstm_model.add(Dense(units=1))\n",
        "\n",
        "# Train the LSTM model\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "lstm_model.fit(train_data, epochs=100, batch_size=32)\n",
        "\n",
        "# Define the CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(1, 1)))\n",
        "cnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(50, activation='relu'))\n",
        "cnn_model.add(Dense(1))\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "cnn_model.fit(train_data, epochs=100, batch_size=32)\n",
        "\n",
        "# Predict parking availability using the trained models\n",
        "lstm_predictions = lstm_model.predict(test_data)\n",
        "lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
        "cnn_predictions = cnn_model.predict(test_data)\n",
        "cnn_predictions = scaler.inverse_transform(cnn_predictions)\n",
        "\n",
        "# Evaluate the models\n",
        "lstm_rmse = np.sqrt(np.mean(np.power((test_data - lstm_predictions), 2)))\n",
        "cnn_rmse = np.sqrt(np.mean(np.power((test_data - cnn_predictions), 2)))\n",
        "\n",
        "print(\"LSTM RMSE: \", lstm_rmse)\n",
        "print(\"CNN RMSE: \", cnn_rmse)\n"
      ],
      "metadata": {
        "id": "h9WgVItZMRow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCVKYXGXMRci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}